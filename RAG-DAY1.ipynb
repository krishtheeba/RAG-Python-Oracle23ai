{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47a5aea-f0a9-4e7c-85f9-8762a63efcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea1f20b-a270-4ca2-b7f0-04d637d2f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" i like to read machnine learning algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445388d-3262-4459-a7b5-e281b7ef224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LookUp Error\n",
    ">>> import nltk\n",
    ">>> nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a7f87-9535-4b94-8808-99fdb0512dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus\n",
    "documents\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b21f41-2e30-4438-987f-3d588a4ce2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'to', 'read', 'machnine', 'learning', 'algorithm']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a7651b-a344-4122-ac2c-9d50e22aa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=''' hello  welcome to Rag training .\n",
    "lets learn NLP , then LLM, Chaining\n",
    "Oracle 23ai, prompting '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5324a2-a417-4e91-948c-c4fdb7a5df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a457137a-1012-4b62-972f-cbab53175174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' hello  welcome to Rag training .', 'lets learn NLP , then LLM, Chaining\\nOracle 23ai, prompting']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b344f6-1f79-4713-9e88-a80fb247c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=\"Hell0 Arun, how are you?. ok. Iam doing well. hos is activities's code \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea0b5f64-5c1a-475e-8c3e-9706316104f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hell0',\n",
       " 'Arun',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " 'ok.',\n",
       " 'Iam',\n",
       " 'doing',\n",
       " 'well',\n",
       " '.',\n",
       " 'hos',\n",
       " 'is',\n",
       " 'activities',\n",
       " \"'s\",\n",
       " 'code']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb14ae8f-75b5-44c3-856f-87740d8dc92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hell0',\n",
       " 'Arun',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?.',\n",
       " 'ok',\n",
       " '.',\n",
       " 'Iam',\n",
       " 'doing',\n",
       " 'well',\n",
       " '.',\n",
       " 'hos',\n",
       " 'is',\n",
       " 'activities',\n",
       " \"'\",\n",
       " 's',\n",
       " 'code']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(msg)|-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767fd93-f70c-45d0-a7eb-544d38a847af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TreebankTokenizer\n",
    "|\n",
    "class\n",
    " |- handles apostrophies\n",
    "|- split punctuation\n",
    "|- adds space \n",
    "\n",
    "can't --> \"ca\"  + \"n't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e9111d-f03c-4356-96eb-2105414673ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method RegexpTokenizer.tokenize of WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL)>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "print(wordpunct_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df39569e-3168-4cf3-8b2c-f50f56f15eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.treebank.TreebankWordTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "print(TreebankWordTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526fd36-4b74-449a-a9f5-dfba9fc781f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk\n",
    "|----tokenize\n",
    "       |-------treebank.py\n",
    "                    |\n",
    "                    class TreeBankTokenizer:\n",
    "                                    def tokenize(self. ):\n",
    "                                         .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fc25e9-4d52-409f-b3c7-9e6e1eeb7695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hell0 Arun, how are you?. ok. Iam doing well. hos is activities's code \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49020eb9-51f2-4958-8f44-d3c5f90e5ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hell0',\n",
       " 'Arun',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " 'ok.',\n",
       " 'Iam',\n",
       " 'doing',\n",
       " 'well.',\n",
       " 'how',\n",
       " 'is',\n",
       " 'activities',\n",
       " \"'s\",\n",
       " 'code',\n",
       " 'ab',\n",
       " \"'s\",\n",
       " 'data1.c']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg=\"Hell0 Arun, how are you?. ok. Iam doing well. how is activities's code  ab's data1.c\"\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "obj=TreebankWordTokenizer()\n",
    "obj.tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb4b482-421a-4581-b353-696900bb3837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp term\n",
    "# Stemming - reduce to the root words\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "obj=PorterStemmer()\n",
    "obj.stem(\"learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3363deaa-d521-4404-998b-e497ae40c65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dde1340-327d-4f6d-9b98-093700d7f046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0acfe1-4324-4fec-9201-c3d237a00fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stem = RegexpStemmer('ing$|s$|es$') # user specific regx pattern\n",
    "reg_stem.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5a5fd10-31f0-4655-a019-01143f4b8107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbfa44-f631-45d2-81ea-12bae35a4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization - Lemma\n",
    "# reducing to root word based pos = v,av,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fdd1616-87ad-43ce-93a5-fd050a053cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma_obj=WordNetLemmatizer()\n",
    "lemma_obj.lemmatize(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a36dda0-014b-416c-bf94-a2b659a384f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_obj.lemmatize(\"eating\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e078d2-544c-4697-b7a6-c24e5a51b7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_obj.lemmatize(\"history\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c170f-3d96-4e4b-82b0-779f5dacab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords - NLP reprocessing\n",
    " |------> do not carry any meaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "341113fd-84a5-4d1a-8270-b47b8549dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc9a6fc5-2718-4853-9a64-9c07c2f4ee33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')\n",
    "stopwords.words('arabic')\n",
    "stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8528b-30bc-428c-a96c-50e5242b2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization---> token - reduce this token to root word- stem-> lemma -> stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b89b067-ad32-41cc-b696-c798ce579213",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gn_list=[\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "         \"writes\",\"programming\",\"program\",\n",
    "         \"history\",\"finally\",\"finalized\"]\n",
    "# import nltk module\n",
    "  #         |-- porterStemmer  - root words\n",
    "  #      |--- WordNetLemmatizer - pos = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e698d3c-be11-4d66-b9af-7e961816f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ----->  word\n",
      "eats ----->  eat\n",
      "eatern ----->  eatern\n",
      "writing ----->  write\n",
      "writes ----->  write\n",
      "programming ----->  program\n",
      "program ----->  program\n",
      "history ----->  histori\n",
      "finally ----->  final\n",
      "finalized ----->  final\n"
     ]
    }
   ],
   "source": [
    "Gn_list=[\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "         \"writes\",\"programming\",\"program\",\n",
    "         \"history\",\"finally\",\"finalized\"]\n",
    "obj=PorterStemmer()\n",
    "for var in Gn_list:\n",
    "    print(f'{var} ----->  {obj.stem(var)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8823186c-e7d0-4879-960d-0839e2ac798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words----> word\n",
      "eats----> eat\n",
      "eatern----> eatern\n",
      "writing----> write\n",
      "writes----> write\n",
      "programming----> program\n",
      "program----> program\n",
      "history----> history\n",
      "finally----> finally\n",
      "finalized----> finalize\n"
     ]
    }
   ],
   "source": [
    "lemma_obj = WordNetLemmatizer()\n",
    "for var in Gn_list:\n",
    "    print(f\"{var}----> { lemma_obj.lemmatize(var,pos='v')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30247224-a6ee-4108-a74e-d9e39c8fc9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example displaying of list or collection of stop words to filter\n"
     ]
    }
   ],
   "source": [
    "msg=\"This is an example displaying of list or collection of stop words to filter\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "144d114e-6349-4165-823f-119ab0556cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'displaying',\n",
       " 'of',\n",
       " 'list',\n",
       " 'or',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'to',\n",
       " 'filter']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39dab93d-bdb6-4a58-9a29-7622551f04e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example\n",
      "displaying\n",
      "list\n",
      "collection\n",
      "stop\n",
      "words\n",
      "filter\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(msg)\n",
    "for var in words:\n",
    "    if var.lower() not in stopwords.words('english'):\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55f1564f-63c4-43a9-8f80-f3fd34a83d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'displaying', 'list', 'collection', 'stop', 'words', 'filter']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_words= [var for var in words if var.lower() not in stopwords.words('english')]  # Functional Style- List comprehension\n",
    "filter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8081f48-dfa0-42e1-aca9-23ceeca9dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task\n",
    "#====\n",
    "Corpus\n",
    "|--- Use PorterStemmer  and WordNetLemmatizer()\n",
    "|--- Apply StopWords\n",
    "|--- Filter remaining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb9b58c2-da88-4b55-86a9-8de0abdd1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Vikram Sarabhai was born on 12 August 1919 in a Gujarati Śvetāmbara Shrimali Jain family, \n",
    "in Ahmedabad, India.His father was Ambalal Sarabhai,\n",
    "a major industrialist committed to the Indian independence movement.\n",
    "Known as the cradle of space sciences in India, the Physical Research Laboratory (PRL) was\n",
    "founded in 1947 by Vikram Sarabhai. PRL had a modest beginning at his residence, the \"RETREAT\", \n",
    "with research on cosmic rays.\n",
    "The institute was formally established at the M.G. Science Institute, Ahmedabad, on 11 November 1947 with support \n",
    "from the Karmkshetra Educational Foundation and the Ahmedabad Education Society. Kalpathi Ramakrishna Ramanathan \n",
    "was the first director of the institute. The initial focus was research on cosmic rays and the properties of the\n",
    "upper atmosphere. Research areas were expanded to include theoretical physics and radio physics later\n",
    "with grants from the Atomic Energy Commission. \n",
    "He led the Sarabhai family-owned business conglomerate.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6904133-be8b-4b74-8410-6feac05ea14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9\n",
      "Vikram Sarabhai was born on 12 August 1919 in a Gujarati Śvetāmbara Shrimali Jain family, \n",
      "in Ahmedabad, India.His father was Ambalal Sarabhai,\n",
      "a major industrialist committed to the Indian independence movement.\n",
      "Known as the cradle of space sciences in India, the Physical Research Laboratory (PRL) was\n",
      "founded in 1947 by Vikram Sarabhai.\n",
      "PRL had a modest beginning at his residence, the \"RETREAT\", \n",
      "with research on cosmic rays.\n",
      "The institute was formally established at the M.G.\n",
      "Science Institute, Ahmedabad, on 11 November 1947 with support \n",
      "from the Karmkshetra Educational Foundation and the Ahmedabad Education Society.\n",
      "Kalpathi Ramakrishna Ramanathan \n",
      "was the first director of the institute.\n",
      "The initial focus was research on cosmic rays and the properties of the\n",
      "upper atmosphere.\n",
      "Research areas were expanded to include theoretical physics and radio physics later\n",
      "with grants from the Atomic Energy Commission.\n",
      "He led the Sarabhai family-owned business conglomerate.\n"
     ]
    }
   ],
   "source": [
    "docs= sent_tokenize(corpus)\n",
    "print(type(docs), len(docs))\n",
    "for var in docs:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f7cdf55-bbfa-420b-8d9a-9378e99175b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vikram', 'Sarabhai', 'was', 'born', 'on', '12', 'August', '1919', 'in', 'a', 'Gujarati', 'Śvetāmbara', 'Shrimali', 'Jain', 'family', ',', 'in', 'Ahmedabad', ',', 'India.His', 'father', 'was', 'Ambalal', 'Sarabhai', ',', 'a', 'major', 'industrialist', 'committed', 'to', 'the', 'Indian', 'independence', 'movement', '.']\n",
      "['Known', 'as', 'the', 'cradle', 'of', 'space', 'sciences', 'in', 'India', ',', 'the', 'Physical', 'Research', 'Laboratory', '(', 'PRL', ')', 'was', 'founded', 'in', '1947', 'by', 'Vikram', 'Sarabhai', '.']\n",
      "['PRL', 'had', 'a', 'modest', 'beginning', 'at', 'his', 'residence', ',', 'the', '``', 'RETREAT', \"''\", ',', 'with', 'research', 'on', 'cosmic', 'rays', '.']\n",
      "['The', 'institute', 'was', 'formally', 'established', 'at', 'the', 'M.G', '.']\n",
      "['Science', 'Institute', ',', 'Ahmedabad', ',', 'on', '11', 'November', '1947', 'with', 'support', 'from', 'the', 'Karmkshetra', 'Educational', 'Foundation', 'and', 'the', 'Ahmedabad', 'Education', 'Society', '.']\n",
      "['Kalpathi', 'Ramakrishna', 'Ramanathan', 'was', 'the', 'first', 'director', 'of', 'the', 'institute', '.']\n",
      "['The', 'initial', 'focus', 'was', 'research', 'on', 'cosmic', 'rays', 'and', 'the', 'properties', 'of', 'the', 'upper', 'atmosphere', '.']\n",
      "['Research', 'areas', 'were', 'expanded', 'to', 'include', 'theoretical', 'physics', 'and', 'radio', 'physics', 'later', 'with', 'grants', 'from', 'the', 'Atomic', 'Energy', 'Commission', '.']\n",
      "['He', 'led', 'the', 'Sarabhai', 'family-owned', 'business', 'conglomerate', '.']\n"
     ]
    }
   ],
   "source": [
    "for var in range(len(docs)):\n",
    "    words= word_tokenize(docs[var])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecbc7b6d-cf61-421c-a0a7-94f1242e9eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vikram\n",
      "sarabhai\n",
      "born\n",
      "12\n",
      "august\n",
      "1919\n",
      "gujarati\n",
      "śvetāmbara\n",
      "shrimali\n",
      "jain\n",
      "family\n",
      ",\n",
      "ahmedabad\n",
      ",\n",
      "india.his\n",
      "father\n",
      "ambalal\n",
      "sarabhai\n",
      ",\n",
      "major\n",
      "industrialist\n",
      "committed\n",
      "indian\n",
      "independence\n",
      "movement\n",
      ".\n",
      "known\n",
      "cradle\n",
      "space\n",
      "sciences\n",
      "india\n",
      ",\n",
      "physical\n",
      "research\n",
      "laboratory\n",
      "(\n",
      "prl\n",
      ")\n",
      "founded\n",
      "1947\n",
      "vikram\n",
      "sarabhai\n",
      ".\n",
      "prl\n",
      "modest\n",
      "beginning\n",
      "residence\n",
      ",\n",
      "``\n",
      "retreat\n",
      "''\n",
      ",\n",
      "research\n",
      "cosmic\n",
      "rays\n",
      ".\n",
      "institute\n",
      "formally\n",
      "established\n",
      "m.g\n",
      ".\n",
      "science\n",
      "institute\n",
      ",\n",
      "ahmedabad\n",
      ",\n",
      "11\n",
      "november\n",
      "1947\n",
      "support\n",
      "karmkshetra\n",
      "educational\n",
      "foundation\n",
      "ahmedabad\n",
      "education\n",
      "society\n",
      ".\n",
      "kalpathi\n",
      "ramakrishna\n",
      "ramanathan\n",
      "first\n",
      "director\n",
      "institute\n",
      ".\n",
      "initial\n",
      "focus\n",
      "research\n",
      "cosmic\n",
      "rays\n",
      "properties\n",
      "upper\n",
      "atmosphere\n",
      ".\n",
      "research\n",
      "areas\n",
      "expanded\n",
      "include\n",
      "theoretical\n",
      "physics\n",
      "radio\n",
      "physics\n",
      "later\n",
      "grants\n",
      "atomic\n",
      "energy\n",
      "commission\n",
      ".\n",
      "led\n",
      "sarabhai\n",
      "family-owned\n",
      "business\n",
      "conglomerate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for var in range(len(docs)):\n",
    "    words= word_tokenize(docs[var])\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            print(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a964e51-c226-4b19-9597-5732912aeb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d541580-3fbf-49cd-bc74-1431c9edff2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28362a40-48b4-49b4-aa0e-374dbb54cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Spark)",
   "language": "python",
   "name": "spark310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
