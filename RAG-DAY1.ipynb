{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47a5aea-f0a9-4e7c-85f9-8762a63efcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea1f20b-a270-4ca2-b7f0-04d637d2f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" i like to read machnine learning algorithm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445388d-3262-4459-a7b5-e281b7ef224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LookUp Error\n",
    ">>> import nltk\n",
    ">>> nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a7f87-9535-4b94-8808-99fdb0512dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus\n",
    "documents\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b21f41-2e30-4438-987f-3d588a4ce2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'to', 'read', 'machnine', 'learning', 'algorithm']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a7651b-a344-4122-ac2c-9d50e22aa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=''' hello  welcome to Rag training .\n",
    "lets learn NLP , then LLM, Chaining\n",
    "Oracle 23ai, prompting '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5324a2-a417-4e91-948c-c4fdb7a5df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a457137a-1012-4b62-972f-cbab53175174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' hello  welcome to Rag training .', 'lets learn NLP , then LLM, Chaining\\nOracle 23ai, prompting']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b344f6-1f79-4713-9e88-a80fb247c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=\"Hell0 Arun, how are you?. ok. Iam doing well. hos is activities's code \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea0b5f64-5c1a-475e-8c3e-9706316104f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hell0',\n",
       " 'Arun',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " 'ok.',\n",
       " 'Iam',\n",
       " 'doing',\n",
       " 'well',\n",
       " '.',\n",
       " 'hos',\n",
       " 'is',\n",
       " 'activities',\n",
       " \"'s\",\n",
       " 'code']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb14ae8f-75b5-44c3-856f-87740d8dc92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hell0',\n",
       " 'Arun',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?.',\n",
       " 'ok',\n",
       " '.',\n",
       " 'Iam',\n",
       " 'doing',\n",
       " 'well',\n",
       " '.',\n",
       " 'hos',\n",
       " 'is',\n",
       " 'activities',\n",
       " \"'\",\n",
       " 's',\n",
       " 'code']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(msg)|-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767fd93-f70c-45d0-a7eb-544d38a847af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TreebankTokenizer\n",
    "|\n",
    "class\n",
    " |- handles apostrophies\n",
    "|- split punctuation\n",
    "|- adds space \n",
    "\n",
    "can't --> \"ca\"  + \"n't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e9111d-f03c-4356-96eb-2105414673ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method RegexpTokenizer.tokenize of WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL)>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "print(wordpunct_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df39569e-3168-4cf3-8b2c-f50f56f15eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.treebank.TreebankWordTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "print(TreebankWordTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526fd36-4b74-449a-a9f5-dfba9fc781f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk\n",
    "|----tokenize\n",
    "       |-------treebank.py\n",
    "                    |\n",
    "                    class TreeBankTokenizer:\n",
    "                                    def tokenize(self. ):\n",
    "                                         .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fc25e9-4d52-409f-b3c7-9e6e1eeb7695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hell0 Arun, how are you?. ok. Iam doing well. hos is activities's code \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49020eb9-51f2-4958-8f44-d3c5f90e5ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hell0',\n",
       " 'Arun',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " 'ok.',\n",
       " 'Iam',\n",
       " 'doing',\n",
       " 'well.',\n",
       " 'how',\n",
       " 'is',\n",
       " 'activities',\n",
       " \"'s\",\n",
       " 'code',\n",
       " 'ab',\n",
       " \"'s\",\n",
       " 'data1.c']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg=\"Hell0 Arun, how are you?. ok. Iam doing well. how is activities's code  ab's data1.c\"\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "obj=TreebankWordTokenizer()\n",
    "obj.tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb4b482-421a-4581-b353-696900bb3837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learn'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp term\n",
    "# Stemming - reduce to the root words\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "obj=PorterStemmer()\n",
    "obj.stem(\"learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3363deaa-d521-4404-998b-e497ae40c65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dde1340-327d-4f6d-9b98-093700d7f046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c0acfe1-4324-4fec-9201-c3d237a00fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stem = RegexpStemmer('ing$|s$|es$') # user specific regx pattern\n",
    "reg_stem.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5a5fd10-31f0-4655-a019-01143f4b8107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stem.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbfa44-f631-45d2-81ea-12bae35a4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization - Lemma\n",
    "# reducing to root word based pos = v,av,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fdd1616-87ad-43ce-93a5-fd050a053cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma_obj=WordNetLemmatizer()\n",
    "lemma_obj.lemmatize(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a36dda0-014b-416c-bf94-a2b659a384f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_obj.lemmatize(\"eating\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e078d2-544c-4697-b7a6-c24e5a51b7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_obj.lemmatize(\"history\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c170f-3d96-4e4b-82b0-779f5dacab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords - NLP reprocessing\n",
    " |------> do not carry any meaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "341113fd-84a5-4d1a-8270-b47b8549dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc9a6fc5-2718-4853-9a64-9c07c2f4ee33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')\n",
    "#stopwords.words('arabic')\n",
    "#stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8528b-30bc-428c-a96c-50e5242b2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization---> token - reduce this token to root word- stem-> lemma -> stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b89b067-ad32-41cc-b696-c798ce579213",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gn_list=[\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "         \"writes\",\"programming\",\"program\",\n",
    "         \"history\",\"finally\",\"finalized\"]\n",
    "# import nltk module\n",
    "  #         |-- porterStemmer  - root words\n",
    "  #      |--- WordNetLemmatizer - pos = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e698d3c-be11-4d66-b9af-7e961816f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ----->  word\n",
      "eats ----->  eat\n",
      "eatern ----->  eatern\n",
      "writing ----->  write\n",
      "writes ----->  write\n",
      "programming ----->  program\n",
      "program ----->  program\n",
      "history ----->  histori\n",
      "finally ----->  final\n",
      "finalized ----->  final\n"
     ]
    }
   ],
   "source": [
    "Gn_list=[\"words\",\"eats\",\"eatern\",\"writing\",\n",
    "         \"writes\",\"programming\",\"program\",\n",
    "         \"history\",\"finally\",\"finalized\"]\n",
    "obj=PorterStemmer()\n",
    "for var in Gn_list:\n",
    "    print(f'{var} ----->  {obj.stem(var)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8823186c-e7d0-4879-960d-0839e2ac798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words----> word\n",
      "eats----> eat\n",
      "eatern----> eatern\n",
      "writing----> write\n",
      "writes----> write\n",
      "programming----> program\n",
      "program----> program\n",
      "history----> history\n",
      "finally----> finally\n",
      "finalized----> finalize\n"
     ]
    }
   ],
   "source": [
    "lemma_obj = WordNetLemmatizer()\n",
    "for var in Gn_list:\n",
    "    print(f\"{var}----> { lemma_obj.lemmatize(var,pos='v')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30247224-a6ee-4108-a74e-d9e39c8fc9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example displaying of list or collection of stop words to filter\n"
     ]
    }
   ],
   "source": [
    "msg=\"This is an example displaying of list or collection of stop words to filter\"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "144d114e-6349-4165-823f-119ab0556cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'displaying',\n",
       " 'of',\n",
       " 'list',\n",
       " 'or',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'to',\n",
       " 'filter']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39dab93d-bdb6-4a58-9a29-7622551f04e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example\n",
      "displaying\n",
      "list\n",
      "collection\n",
      "stop\n",
      "words\n",
      "filter\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(msg)\n",
    "for var in words:\n",
    "    if var.lower() not in stopwords.words('english'):\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55f1564f-63c4-43a9-8f80-f3fd34a83d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'displaying', 'list', 'collection', 'stop', 'words', 'filter']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_words= [var for var in words if var.lower() not in stopwords.words('english')]  # Functional Style- List comprehension\n",
    "filter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8081f48-dfa0-42e1-aca9-23ceeca9dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task\n",
    "#====\n",
    "Corpus\n",
    "|--- Use PorterStemmer  and WordNetLemmatizer()\n",
    "|--- Apply StopWords\n",
    "|--- Filter remaining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb9b58c2-da88-4b55-86a9-8de0abdd1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Vikram Sarabhai was born on 12 August 1919 in a Gujarati Śvetāmbara Shrimali Jain family, \n",
    "in Ahmedabad, India.His father was Ambalal Sarabhai,\n",
    "a major industrialist committed to the Indian independence movement.\n",
    "Known as the cradle of space sciences in India, the Physical Research Laboratory (PRL) was\n",
    "founded in 1947 by Vikram Sarabhai. PRL had a modest beginning at his residence, the \"RETREAT\", \n",
    "with research on cosmic rays.\n",
    "The institute was formally established at the M.G. Science Institute, Ahmedabad, on 11 November 1947 with support \n",
    "from the Karmkshetra Educational Foundation and the Ahmedabad Education Society. Kalpathi Ramakrishna Ramanathan \n",
    "was the first director of the institute. The initial focus was research on cosmic rays and the properties of the\n",
    "upper atmosphere. Research areas were expanded to include theoretical physics and radio physics later\n",
    "with grants from the Atomic Energy Commission. \n",
    "He led the Sarabhai family-owned business conglomerate.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6904133-be8b-4b74-8410-6feac05ea14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9\n",
      "Vikram Sarabhai was born on 12 August 1919 in a Gujarati Śvetāmbara Shrimali Jain family, \n",
      "in Ahmedabad, India.His father was Ambalal Sarabhai,\n",
      "a major industrialist committed to the Indian independence movement.\n",
      "Known as the cradle of space sciences in India, the Physical Research Laboratory (PRL) was\n",
      "founded in 1947 by Vikram Sarabhai.\n",
      "PRL had a modest beginning at his residence, the \"RETREAT\", \n",
      "with research on cosmic rays.\n",
      "The institute was formally established at the M.G.\n",
      "Science Institute, Ahmedabad, on 11 November 1947 with support \n",
      "from the Karmkshetra Educational Foundation and the Ahmedabad Education Society.\n",
      "Kalpathi Ramakrishna Ramanathan \n",
      "was the first director of the institute.\n",
      "The initial focus was research on cosmic rays and the properties of the\n",
      "upper atmosphere.\n",
      "Research areas were expanded to include theoretical physics and radio physics later\n",
      "with grants from the Atomic Energy Commission.\n",
      "He led the Sarabhai family-owned business conglomerate.\n"
     ]
    }
   ],
   "source": [
    "docs= sent_tokenize(corpus)\n",
    "print(type(docs), len(docs))\n",
    "for var in docs:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f7cdf55-bbfa-420b-8d9a-9378e99175b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vikram', 'Sarabhai', 'was', 'born', 'on', '12', 'August', '1919', 'in', 'a', 'Gujarati', 'Śvetāmbara', 'Shrimali', 'Jain', 'family', ',', 'in', 'Ahmedabad', ',', 'India.His', 'father', 'was', 'Ambalal', 'Sarabhai', ',', 'a', 'major', 'industrialist', 'committed', 'to', 'the', 'Indian', 'independence', 'movement', '.']\n",
      "['Known', 'as', 'the', 'cradle', 'of', 'space', 'sciences', 'in', 'India', ',', 'the', 'Physical', 'Research', 'Laboratory', '(', 'PRL', ')', 'was', 'founded', 'in', '1947', 'by', 'Vikram', 'Sarabhai', '.']\n",
      "['PRL', 'had', 'a', 'modest', 'beginning', 'at', 'his', 'residence', ',', 'the', '``', 'RETREAT', \"''\", ',', 'with', 'research', 'on', 'cosmic', 'rays', '.']\n",
      "['The', 'institute', 'was', 'formally', 'established', 'at', 'the', 'M.G', '.']\n",
      "['Science', 'Institute', ',', 'Ahmedabad', ',', 'on', '11', 'November', '1947', 'with', 'support', 'from', 'the', 'Karmkshetra', 'Educational', 'Foundation', 'and', 'the', 'Ahmedabad', 'Education', 'Society', '.']\n",
      "['Kalpathi', 'Ramakrishna', 'Ramanathan', 'was', 'the', 'first', 'director', 'of', 'the', 'institute', '.']\n",
      "['The', 'initial', 'focus', 'was', 'research', 'on', 'cosmic', 'rays', 'and', 'the', 'properties', 'of', 'the', 'upper', 'atmosphere', '.']\n",
      "['Research', 'areas', 'were', 'expanded', 'to', 'include', 'theoretical', 'physics', 'and', 'radio', 'physics', 'later', 'with', 'grants', 'from', 'the', 'Atomic', 'Energy', 'Commission', '.']\n",
      "['He', 'led', 'the', 'Sarabhai', 'family-owned', 'business', 'conglomerate', '.']\n"
     ]
    }
   ],
   "source": [
    "for var in range(len(docs)):\n",
    "    words= word_tokenize(docs[var])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecbc7b6d-cf61-421c-a0a7-94f1242e9eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vikram\n",
      "sarabhai\n",
      "born\n",
      "12\n",
      "august\n",
      "1919\n",
      "gujarati\n",
      "śvetāmbara\n",
      "shrimali\n",
      "jain\n",
      "family\n",
      ",\n",
      "ahmedabad\n",
      ",\n",
      "india.his\n",
      "father\n",
      "ambalal\n",
      "sarabhai\n",
      ",\n",
      "major\n",
      "industrialist\n",
      "committed\n",
      "indian\n",
      "independence\n",
      "movement\n",
      ".\n",
      "known\n",
      "cradle\n",
      "space\n",
      "sciences\n",
      "india\n",
      ",\n",
      "physical\n",
      "research\n",
      "laboratory\n",
      "(\n",
      "prl\n",
      ")\n",
      "founded\n",
      "1947\n",
      "vikram\n",
      "sarabhai\n",
      ".\n",
      "prl\n",
      "modest\n",
      "beginning\n",
      "residence\n",
      ",\n",
      "``\n",
      "retreat\n",
      "''\n",
      ",\n",
      "research\n",
      "cosmic\n",
      "rays\n",
      ".\n",
      "institute\n",
      "formally\n",
      "established\n",
      "m.g\n",
      ".\n",
      "science\n",
      "institute\n",
      ",\n",
      "ahmedabad\n",
      ",\n",
      "11\n",
      "november\n",
      "1947\n",
      "support\n",
      "karmkshetra\n",
      "educational\n",
      "foundation\n",
      "ahmedabad\n",
      "education\n",
      "society\n",
      ".\n",
      "kalpathi\n",
      "ramakrishna\n",
      "ramanathan\n",
      "first\n",
      "director\n",
      "institute\n",
      ".\n",
      "initial\n",
      "focus\n",
      "research\n",
      "cosmic\n",
      "rays\n",
      "properties\n",
      "upper\n",
      "atmosphere\n",
      ".\n",
      "research\n",
      "areas\n",
      "expanded\n",
      "include\n",
      "theoretical\n",
      "physics\n",
      "radio\n",
      "physics\n",
      "later\n",
      "grants\n",
      "atomic\n",
      "energy\n",
      "commission\n",
      ".\n",
      "led\n",
      "sarabhai\n",
      "family-owned\n",
      "business\n",
      "conglomerate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for var in range(len(docs)):\n",
    "    words= word_tokenize(docs[var])\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            print(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a964e51-c226-4b19-9597-5732912aeb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data1', 'data2'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L=['data1','data2','data1','data1'] \n",
    "set(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "073d8d88-8832-49bc-82db-2b09d384bf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data1', 'data2']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "980d517c-3dc5-469e-9fac-3a1543af5318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vikram sarabhai born 12 august 1919 gujarati śvetāmbara shrimali jain famili , ahmedabad , india.hi father ambal sarabhai , major industrialist commit indian independ movement .',\n",
       " 'known cradl space scienc india , physic research laboratori ( prl ) found 1947 vikram sarabhai .',\n",
       " \"prl modest begin resid , `` retreat '' , research cosmic ray .\",\n",
       " 'the institut formal establish m.g .',\n",
       " 'scienc institut , ahmedabad , 11 novemb 1947 support karmkshetra educ foundat ahmedabad educ societi .',\n",
       " 'kalpathi ramakrishna ramanathan first director institut .',\n",
       " 'the initi focu research cosmic ray properti upper atmospher .',\n",
       " 'research area expand includ theoret physic radio physic later grant atom energi commiss .',\n",
       " 'he led sarabhai family-own busi conglomer .']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stem_obj=PorterStemmer()\n",
    "docs= nltk.sent_tokenize(corpus)\n",
    "\n",
    "for var in range(len(docs)):\n",
    "    words=nltk.word_tokenize(docs[var])\n",
    "    words= [stem_obj.stem(word)for word in words if word not in stopwords.words('english')]\n",
    "    docs[var] =\" \". join(words)\n",
    "\n",
    "docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ece84480-22e8-470e-a2a3-b8130439468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', bear major 12 . Sarabhai father Ambalal Shrimali Gujarati August Jain movement Indian Śvetāmbara independence commit family industrialist Ahmedabad India.His 1919 Vikram',\n",
       " 'Sarabhai sciences space Research found Known 1947 Laboratory . Physical Vikram , ( ) PRL cradle India',\n",
       " \"RETREAT `` research begin , '' residence cosmic ray modest PRL .\",\n",
       " 'The institute formally establish M.G .',\n",
       " 'Educational 1947 support . Ahmedabad November Science Foundation Institute 11 , Society Karmkshetra Education',\n",
       " 'Kalpathi institute director Ramakrishna Ramanathan first .',\n",
       " 'research atmosphere upper focus The initial ray properties cosmic .',\n",
       " 'Research physics theoretical include Energy areas radio later Commission grant Atomic . expand',\n",
       " 'Sarabhai conglomerate business lead He family-owned .']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use LEmmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "docs= nltk.sent_tokenize(corpus)\n",
    "\n",
    "for var in range(len(docs)):\n",
    "    words=nltk.word_tokenize(docs[var])\n",
    "    words= [lemmatizer.lemmatize(word,pos=\"v\")for word in words if word not in stopwords.words('english')]\n",
    "    l=set(words)\n",
    "    words=list(l)\n",
    "    docs[var] =\" \". join(words)\n",
    "\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1443c19-715e-4abb-8d71-34bbc459d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram technique\n",
    "===============\n",
    "    An n-gram - continuous sequence of n items from a corpus\n",
    "\n",
    "food good bad => after lemmatization and filting stopwords\n",
    "n=3 => no. of unique\n",
    "\n",
    "n=1\n",
    "food --> 1 0 0 --> [1 0 0 ]\n",
    "good --> 0 1 1  -> [0 1 0]\n",
    "bad --> 0 0 1  ->  [ 0 0 1]\n",
    "\n",
    "\n",
    "n=2\n",
    "---\n",
    "food good   ->  1 0\n",
    "----------   \n",
    "good bad    ---> 0 1\n",
    "\n",
    "n=3\n",
    "food good bad  -> 1\n",
    "                  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1dfc708b-cdb3-466c-90ad-4926290710c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ec36c1c-b9d7-4eab-bdd3-5b23d6513504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['likes', 'read', 'nlp', 'applications']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=\"likes read nlp applications\"\n",
    "word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f29222dd-080b-42fd-a8ac-48a7aebb344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x000001EE457E9A40>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token= word_tokenize(data)\n",
    "ngrams(token,1)  # unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf3297-64ae-40af-b154-cdb53b3ac82f",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def f1():\n",
    "...     return 10\n",
    "...\n",
    ">>> f1()\n",
    "10\n",
    ">>> def f2():\n",
    "...     yield 10\n",
    "...\n",
    ">>> f2()\n",
    "<generator object f2 at 0x0000014514D6C5F0>\n",
    ">>> # function returns an iterator obj--> generator\n",
    ">>>\n",
    ">>> next(f2())\n",
    "10\n",
    ">>>\n",
    ">>> for var in f2():\n",
    "...     print(var)\n",
    "...\n",
    "10\n",
    ">>> list(f2())\n",
    "[10]\n",
    ">>> def f3():\n",
    "...     yield 10\n",
    "...     yield [1,2,3]\n",
    "...     yield 1,\n",
    "...\n",
    ">>> f3()\n",
    "<generator object f3 at 0x0000014514D6DE00>\n",
    ">>> next(f3())\n",
    "10\n",
    ">>> next(f3())\n",
    "10\n",
    ">>> next(f3())\n",
    "10\n",
    ">>> for var in f3():\n",
    "...     print(var)\n",
    "...\n",
    "10\n",
    "[1, 2, 3]\n",
    "(1,)\n",
    ">>> list(f3())\n",
    "[10, [1, 2, 3], (1,)]\n",
    ">>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe49a40c-14e1-4d95-b230-3c1ee5c0a3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes',), ('read',), ('nlp',), ('applications',)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(token,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef540c20-1e3f-4ec5-8168-72632262fcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read'), ('read', 'nlp'), ('nlp', 'applications')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(token,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77f3e954-56ae-4ed2-8bf2-e90c8ddae492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read', 'nlp'), ('read', 'nlp', 'applications')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(token,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b362b6d-f653-49db-a3d0-557f8c56e748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('likes', 'read', 'nlp', 'applications')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(token,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92b4f37b-c3a3-44c2-99ef-12a1bdd8dc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(token,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab0f0837-6fe8-4d8b-9a24-0523c6fd103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['bad', 'food', 'good'], dtype='<U4')]\n",
      "\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "data=['food', 'good', 'bad']\n",
    "\n",
    "data= np.array(data).reshape(-1,1) # 2D\n",
    "\n",
    "encoder_obj=OneHotEncoder(sparse_output=False)\n",
    "one_hot=encoder_obj.fit_transform(data)\n",
    "print(encoder_obj.categories_)\n",
    "print('')\n",
    "print(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c67d611-e1ee-48fa-a7cf-e55a168a6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['father', 'he', 'indian', 'program', 'regards', 'space', 'widely'],\n",
      "      dtype='<U7')]\n",
      "\n",
      "[[0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data=[\"he\",\"widely\",\"regards\",\"father\", \"indian\",\"space\",\"program\"]\n",
    "data= np.array(data).reshape(-1,1) # 2D\n",
    "\n",
    "encoder_obj=OneHotEncoder(sparse_output=False)\n",
    "one_hot=encoder_obj.fit_transform(data)\n",
    "print(encoder_obj.categories_)\n",
    "print('')\n",
    "print(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c1805-ac7e-48ad-9575-817de976c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try \n",
    "#pip install scikit-learn\n",
    "#import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8470b7d6-8e80-4076-8d9f-db5133fb8d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([10,20,30]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffb70a02-ebe6-4e83-a1ae-0b996e366b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([10,20,30,30.0]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e42f19b-6a15-418f-b80d-aa4cf4fae522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U21')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([10,20,30,'data']).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "476617a1-b099-4a0e-bd69-1ccdd490b5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([[10,20,30,40,50,60]])\n",
    "arr.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c868b123-a18b-4320-94e3-2e8abbfb2cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 20 30 40 50 60]]\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6fce1c6e-8aa2-4562-a06d-117c1dc004a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30],\n",
       "       [40, 50, 60]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.reshape(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5f753d1-613c-4842-a83a-c478eda34073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e740e45-8ab5-4ac0-ae26-772ab8453369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'courses' 'likes' 'nlp' 'python']\n",
      "[[1 0 2 1 1]\n",
      " [1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "docs=[\"i likes nlp and i likes python\", \"python and nlp courses\"]\n",
    "cv=CountVectorizer()\n",
    "bow= cv.fit_transform(docs) # bag of words\n",
    "print(cv.get_feature_names_out())\n",
    "print(bow.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceaf962-211c-4883-a7cd-3c2a7ca966b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF- IDF\n",
    "Term Frequency- Inverse Document Frequency\n",
    "\n",
    "s1--> good boy\n",
    "s2--> good girl\n",
    "s3--> boy girl good\n",
    "\n",
    "TF=no. of repeatation of a specific word\n",
    "   -------------------------------------\n",
    "    no. of words in sentence\n",
    "\n",
    "IDF= log (    no. of sentence / no.of sentences containing word)\n",
    "\n",
    "TF\n",
    "===\n",
    "        s1     s2    s3\n",
    "good    1/2    1/2   1/3\n",
    "boy     1/2    0/2   1/3\n",
    "girl    0/2    1/2   1/3\n",
    "\n",
    "IDF\n",
    "===\n",
    "\n",
    "words\n",
    "good    log(3/3)\n",
    "girl    log(3/2)\n",
    "boy     log(3/2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8ff34fe-b0e1-4568-ab10-bdd164d48a2f",
   "metadata": {},
   "source": [
    "from genism.models import Word2Vec\n",
    "docs= [[\"the\",\"cat\",\"sat\",\"on\",\"the\",\"mat\"],\n",
    "        [\"the\",\"dog\",\"sat\",\"on\",\"the\",\"log\"]]\n",
    "model=Word2Vec(docs,vector_size=50)\n",
    "model.wv.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6655c-982a-41c8-a6c0-136c420fc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer - Encoder + Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e2069-3361-40bc-b3c0-2c98019f0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain\n",
    "|------OpenSource Framework - genAI Appln\n",
    "|\n",
    "|\n",
    "|---- use LLM\n",
    "| ---- connect data with LLM\n",
    "\n",
    "    Components\n",
    "    ----------\n",
    "    1. chain\n",
    "    2. Prompt management\n",
    "    3. Vector DB\n",
    "    4. Model\n",
    "    5. Memory\n",
    "    6. Agent\n",
    "\n",
    "    ex: explain about python -- Q1\n",
    "    .....................................\n",
    "    give me 5 features  --Q2\n",
    "     ..............................\n",
    "\n",
    "|---> community documents\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f32268-b6f5-4cba-8109-3ffb622818f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Data Loading from various sources - text file, pdf, web, wikipedia... // loader class\n",
    "2. Split data into multiple chunks\n",
    "3. using embedding model-- > chunks--> vectors\n",
    "4. stores in vectorDB\n",
    "5. similarity search\n",
    "------------------------------------------//\n",
    "6. llm\n",
    "7. prompt\n",
    "8. chain\n",
    "9. outputparser\n",
    "10.userinterface - streamlit, flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db13b19-fa0f-40ee-ac8e-7e75e8febbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\karth>ollama --version\n",
    "ollama version is 0.13.5\n",
    "\n",
    "C:\\Users\\karth>ollama -V\n",
    "Error: unknown shorthand flag: 'V' in -V\n",
    "\n",
    "C:\\Users\\karth>ollama -v\n",
    "ollama version is 0.13.5\n",
    "\n",
    "C:\\Users\\karth>ollama list\n",
    "NAME                       ID              SIZE      MODIFIED\n",
    "gemma2:2b                  8ccf136fdd52    1.6 GB    19 hours ago\n",
    "nomic-embed-text:latest    0a109f422b47    274 MB    19 hours ago\n",
    "\n",
    "C:\\Users\\karth># ollama pull <modelname>   # To download model\n",
    "The system cannot find the file specified.\n",
    "\n",
    "C:\\Users\\karth># ollama run <modelname> # To run a model\n",
    "The system cannot find the file specified.\n",
    "\n",
    "C:\\Users\\karth>ollama list\n",
    "NAME                       ID              SIZE      MODIFIED\n",
    "gemma2:2b                  8ccf136fdd52    1.6 GB    19 hours ago\n",
    "nomic-embed-text:latest    0a109f422b47    274 MB    19 hours ago\n",
    "\n",
    "C:\\Users\\karth>ollama rm <modelname>\n",
    "The syntax of the command is incorrect.\n",
    "\n",
    "C:\\Users\\karth>ollama run gemma2:2b\n",
    ">>> what is langchain?\n",
    "LangChain is a powerful framework for building applications using large language models (LLMs).  Think of it like\n",
    "a toolkit that helps developers combine LLMs with other data and tools to create more complex and versatile AI\n",
    "experiences.\n",
    "\n",
    "**Here's the lowdown:**\n",
    "\n",
    "* **What it does:** LangChain streamlines the process of integrating LLMs into your applications, offering\n",
    "features such as:\n",
    "    * **Memory**:  Store information about previous interactions with your LLM for context and conversational flow\n",
    "(like a chatbot!).\n",
    "    * **Chains**: Create sequences of commands to achieve complex tasks. Think \"summarize this article, then\n",
    "generate different marketing copy based on the summary.\"\n",
    "    * **Agents:** Build autonomous agents that can interact with various environments and make decisions based on\n",
    "their understanding.\n",
    "    * **Data Integration:** Connect your LLMs to external data sources like APIs, databases, and documents to\n",
    "access relevant information for more accurate responses.\n",
    "\n",
    "* **Who it's for:**  LangChain is a valuable tool for:\n",
    "    * Developers who want to build powerful LLM applications like chatbots, question-answer systems, or text\n",
    "summarizers.\n",
    "    * Businesses looking to automate processes and improve efficiency with AI.\n",
    "    * Researchers working on advanced AI models.\n",
    "\n",
    "**Analogy:** Imagine you're writing a story (the LLM is your character). LangChain helps you give your story more\n",
    "depth and purpose by:\n",
    " *  Creating a storyline based on different data points like plot twists or information from real life.\n",
    " *  Linking characters to specific environments for richer interactions.\n",
    "\n",
    "\n",
    "**In a nutshell:** LangChain makes it easier to work with LLMs and build innovative applications powered by AI.\n",
    "\n",
    "**To learn more, check out:**\n",
    "\n",
    "* **\n",
    "\n",
    ">>>\n",
    "\n",
    "C:\\Users\\karth>ollama list\n",
    "NAME                       ID              SIZE      MODIFIED\n",
    "gemma2:2b                  8ccf136fdd52    1.6 GB    19 hours ago\n",
    "nomic-embed-text:latest    0a109f422b47    274 MB    19 hours ago\n",
    "\n",
    "C:\\Users\\karth>ollama run nomic-embed-text:latest\n",
    "Error: embedding models require input text. Usage: ollama run nomic-embed-text:latest \"your text here\"\n",
    "\n",
    "C:\\Users\\karth>ollama run nomic-embed-text:latest \"hello\"\n",
    "[0.017860368,-0.005880318,-0.17529128,-0.013721276,0.03403859,0.044752814,0.012422824,-0.0025509228,-0.014760505,-0.03928757,-0.009200146,0.051717155,0.05771218,0.057226323,0.045014214,-0.05359758,0.028783012,-0.047195476,-0.039058723,0.026992228,0.009364105,-0.06674605,0.004949517,-0.0058987713,0.17222914,-0.004382981,0.01864732,0.083406255,0.0016174744,-0.02250796,0.02034864,-0.018761951,0.015323926,0.0032324812,0.02755448,-0.01871097,-0.0038496028,0.011239505,0.016208217,0.01929364,-0.01764852,-0.009595988,0.009243244,-0.02831918,0.05137727,0.007274074,-0.022126125,0.013326626,0.053705517,-0.043480553,-0.003986369,-0.00420693,-0.022152327,0.04244238,0.033516046,0.05497025,0.057901107,0.020405494,0.021781452,0.025755676,0.037800968,0.047367595,0.019435268,0.07026823,-0.0026357146,-0.032041043,-0.010766219,0.03776245,0.047613546,-0.004171873,0.07182922,0.0026584587,0.018865246,-0.0024502345,0.015050562,0.02064043,0.0057850573,-0.029026812,-0.024805265,-0.037957177,0.030283615,-0.061501738,0.073149055,-0.05746802,0.016398309,-0.031170418,-0.018681915,-0.00021392228,-0.052027125,0.0069116903,0.04949368,0.0063920305,-0.011707167,0.037248943,-0.038340807,0.005969399,-0.031469993,0.00048377286,-0.051756456,-0.056019537,-0.0056988457,0.019381372,-0.004601417,0.008907521,0.057604685,0.043122116,-0.036950637,-0.038359072,-0.037678033,-0.030469624,-0.053724006,0.023722827,-0.012083642,0.0045474246,0.0004580619,0.0046509188,0.03941937,-0.09525451,0.040553935,0.038455192,-0.071363114,0.01063518,0.0049926974,0.039715204,0.02650702,0.04915366,-0.090285555,-0.014988227,-0.004449548,0.010545871,0.006581031,-0.034487534,-0.009414395,-0.034195054,0.034734555,0.0096996445,-0.040370632,-0.02164169,0.03675973,0.009738772,0.020242564,0.018505812,0.023278851,-0.049513616,-0.035538286,-0.03042774,0.07503323,-0.04826561,0.017414741,-0.007243618,0.014306152,0.039287634,0.021788498,0.0038678648,0.026368232,-0.016929219,-0.012645982,0.00033233236,0.03874378,-0.03079375,0.010665363,-0.032959554,-0.047336094,0.007695892,-0.008897357,-0.058269072,0.0018215001,0.041220505,0.04596221,0.040155023,-0.012623088,-0.04596179,-0.01109474,-0.0026871243,-0.0032333403,0.004236132,-0.008210016,-0.06381824,0.024798958,-0.011827391,0.019828474,-0.058038324,0.028569378,0.031238642,-0.03819286,-0.02094438,0.002618026,0.01238333,-0.015436716,-0.02661699,-0.031351525,0.006939414,-0.059028044,-0.037714414,-0.011104786,-0.017169239,0.026147157,0.016324643,0.055456575,-0.030510584,-0.050826624,-0.012130352,-0.0041694613,0.0016681238,0.014953969,0.09705322,0.02925681,0.028252965,0.03444062,0.01890566,0.08541962,-0.061635673,-0.03431772,-0.019245988,-0.003208898,0.0019301319,0.02777815,-0.029603686,0.002282565,0.024885366,0.025125014,-0.040680807,0.021241548,-0.009766724,0.046550773,-0.023384215,-0.01427931,0.0000913809,-0.07296258,0.019429972,-0.055853125,-0.05012878,0.030918408,0.020453941,-0.0071502086,0.02185678,0.045257933,0.06415905,-0.008021594,-0.027324775,-0.029933115,0.047874913,0.040672354,0.0047284765,-0.06622185,0.025268964,-0.017620454,0.0075680357,0.0054270243,0.0049950797,-0.018857457,-0.009234486,-0.034252226,0.03152015,0.033934735,-0.042542856,-0.036943335,0.024518978,-0.024489524,-0.044251844,0.026629118,-0.09310856,0.018127864,-0.060437508,-0.0508711,0.017333586,-0.04829309,0.008386456,0.04344447,-0.034073085,0.0013360814,0.013198015,0.015223831,0.035051033,-0.031234741,-0.0001792367,0.0054944297,0.020193951,-0.041197915,-0.009368439,-0.018181663,-0.043087266,-0.05926647,-0.026738228,0.0050344523,0.04492033,0.022938237,0.02958477,-0.009887955,0.011340574,0.024117457,0.013106258,0.026926212,0.065281786,-0.02627884,0.002793322,0.028257102,0.017976902,-0.038332406,-0.0129609015,-0.022483079,0.046461392,0.054434273,-0.034493726,-0.0033156795,0.0044139246,0.030413,-0.023233037,0.056663495,0.018557344,-0.070695676,0.038192965,-0.06515675,-0.006850395,-0.039724577,0.025936488,-0.009006914,0.035830803,0.07508239,0.046541434,-0.021216422,-0.048905507,-0.006012207,-0.04947853,0.016443454,0.020270621,0.026076844,0.061514307,0.034111444,-0.027095636,0.023973402,0.011644986,-0.048252948,-0.027199566,-0.02832465,0.036500458,0.010683915,-0.0051506013,-0.026388157,0.07393915,0.021655383,-0.024513444,0.02419472,-0.02017595,-0.024184378,-0.038734443,-0.017109146,0.0026636356,-0.026333401,-0.0106397085,-0.018606879,0.04707917,-0.031181157,0.027668813,0.0133915935,-0.00034284923,0.03221943,0.039296664,0.01374417,-0.026111495,-0.0053435992,-0.012217772,0.035472665,-0.0061222934,-0.039127495,0.028643362,0.01404635,0.008591807,0.034330428,0.012886857,-0.04409949,-0.02330491,-0.0069598122,0.03441854,0.03888655,0.015615262,-0.084011115,-0.038742494,0.014238609,0.00751673,-0.013170077,-0.011105788,0.040688254,-0.03828955,0.03980857,0.048281536,0.038280964,0.0025481798,0.0041990476,0.008878313,-0.0013026483,-0.001331895,-0.015143568,0.015507365,-0.0119528035,-0.0022658708,0.045437068,0.011907441,-0.022507694,-0.004864644,-0.029614126,0.0024063191,0.0102991825,-0.08083363,0.006650415,0.0135130705,-0.031900633,-0.027494408,-0.0025165963,-0.02822683,0.05575717,0.0015283172,0.014701263,-0.043647543,-0.004215854,0.014708069,0.04395805,-0.04150607,-0.029946247,0.019263383,0.045574304,0.05060934,0.026141245,0.0016133827,-0.013278699,0.077146985,0.02009641,0.043369435,0.020181732,-0.06437711,-0.0071234875,0.0033943565,0.039469622,0.029090703,-0.033232905,-0.029116284,0.015271585,-0.016118359,0.0103869615,0.02288849,0.057662528,-0.0246532,-0.07397761,0.0021622127,0.03032581,0.117301,0.09918122,-0.035232686,-0.0642044,-0.015739717,0.013315119,0.021038763,0.018458819,0.006688024,0.08229004,-0.059372917,0.045015343,-0.0057618134,0.010266579,0.029558046,0.031448506,0.022635257,-0.016209606,0.0011044247,-0.004363984,-0.052405946,0.01135951,-0.008062068,0.0032934418,0.03564111,-0.060261127,-0.032563154,0.014903902,-0.027944176,-0.039704114,0.020810151,0.009385864,-0.01787266,0.0035187986,0.036082048,0.010764196,0.0113635445,-0.06660004,-0.020061133,0.015656631,0.048048824,-0.0005256818,0.03099477,0.011989968,0.021285718,0.026121616,0.0061695976,0.027883923,0.011993503,-0.006467747,-0.0103724,-0.062004033,0.035940234,-0.025783872,-0.016484525,0.0050060055,0.011853178,-0.009114532,0.023922246,0.0060655917,0.005141192,0.02898987,-0.07712731,-0.019418575,0.0059240474,-0.010793916,0.010919627,-0.0061062165,0.03880744,0.06345246,-0.042004537,0.031718977,-0.017401738,-0.044112615,0.0747718,-0.004649097,-0.0663012,0.0023077214,0.014370927,-0.08108808,0.05810594,-0.0098635405,-0.010505452,0.04310117,0.015184307,-0.0010166687,0.0018214029,-0.023633752,-0.051898807,-0.0012805666,-0.00909261,-0.019815547,0.03663618,0.0047921995,0.009491083,-0.054922212,0.020989453,-0.004306235,-0.01745168,0.03984779,0.033778317,-0.033686288,-0.011724957,0.024946703,-0.0035487674,-0.023116084,-0.056529507,-0.004255076,-0.041630194,-0.04097412,-0.07299581,-0.01594963,0.010920403,-0.026863143,-0.053734045,0.07538777,0.02826151,-0.000058346475,-0.008094224,0.032333046,-0.018395742,0.0063174576,-0.03530382,-0.0026941656,-0.021775596,-0.016231509,-0.05567346,0.051096987,-0.04112871,-0.0017323175,0.016996175,0.031434763,-0.0026465906,-0.07406271,-0.025550839,-0.0047113346,-0.014053704,-0.023840062,0.053761546,-0.009728622,0.01951716,0.0028435765,-0.052222647,0.054105416,-0.016960192,-0.006534154,0.0032998833,0.030624973,-0.026571628,-0.01745271,0.06300624,-0.010783237,-0.06170387,-0.018715609,-0.015941624,-0.02903186,0.002297035,0.06187133,-0.044788357,-0.010245513,0.076383874,0.037700344,0.044386957,0.006285001,-0.0061902553,0.062444326,0.03476711,-0.030283973,0.016273914,0.046589866,-0.015218305,-0.014543282,-0.013322764,0.01598687,-0.046202023,-0.032922745,-0.026151711,0.046480123,0.0102628,0.02552239,-0.024694202,-0.04055441,-0.04307006,-0.03344652,0.052090324,0.023056895,-0.04306217,-0.09566476,-0.014106147,0.0032079988,0.026800795,0.033734523,0.004543458,0.002738151,0.034778085,0.09816091,-0.011866037,0.03020925,0.011511038,0.047920268,-0.019795157,0.027167229,0.020326687,0.038437374,0.010024084,0.059958514,0.039668918,0.024629563,0.02159634,-0.0031092463,-0.02409649,0.01823242,-0.017688427,-0.08733394,0.022539994,-0.024013005,0.016363977,-0.09067748,-0.0679618,0.04147759,-0.012693609,-0.013115287,0.030227074,-0.07169155,-0.0053778253,-0.011092428,-0.028297486,-0.014734586,-0.03916293,-0.058031645,0.052158352,0.049460802,0.016630404,0.040639002,-0.00719335,-0.011894629,-0.014261786,-0.010812772,0.04620517,0.030914685,-0.06875327,0.05932612,0.0021244965,-0.05010033,-0.08525335,-0.0031635282,-0.053415418,-0.009147353,-0.0030396504,-0.036380604,-0.0014916657,-0.020501561,0.028144194,-0.032128256,0.051824983,-0.05831513,-0.010667104,0.004964954,0.02252253,-0.014235271,-0.013571326,-0.004053372,0.034637667,-0.041326713,-0.00037538842,-0.012151706,0.046991467,0.009692152,0.05944107,0.0105869565,0.004659791,-0.038019434,-0.002789343,-0.0077159847,0.06181793,0.08557673,0.017828688,-0.051017895,-0.022311732,-0.036231857,0.0005840571,0.022685673,-0.029610926,0.006322717,-0.03453666,-0.01342647,-0.018374298,-0.059802104,0.0456527,-0.016767176,0.0072272797,-0.00025763386,-0.075691685,-0.010423527,-0.011642503,-0.04580213,-0.070801035,-0.0017079357,0.09042611,-0.0010576012,-0.04610344,0.030724194,0.03259058,-0.021382995,-0.007199502,0.029605513,-0.0046130884,-0.016326057,-0.015416303,0.0285162,0.011845546,-0.007296305,0.04587301,0.05762016,-0.030737147,0.048767455,-0.010170026,0.015620471,0.026530715,0.0021643108,-0.014142397,-0.07688886,-0.019889472]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794e996-93bb-4ccb-9a6a-f811665d3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt  \n",
    "inside Jupyter\n",
    "|\n",
    "! pip install -r requirements.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "681f944c-7d60-4e64-9ea0-4a15b2f0e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1513c41-b6c2-4ae7-b255-9033e190bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_ollama.llms.OllamaLLM'>\n"
     ]
    }
   ],
   "source": [
    "print(OllamaLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "364550f7-afd2-4f11-acce-29e281662a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_ollama\\\\__init__.py'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_ollama\n",
    "langchain_ollama.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87975a06-48eb-4639-a035-b4e76a869552",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_ollama\n",
    "          |--------llms.py\n",
    "                    |-------class OllamaLLM:\n",
    "                             ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0064816e-3152-4106-97e7-0da5b40fd3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2214\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm_obj=OllamaLLM(model=\"gemma2:2b\")\n",
    "result= llm_obj.invoke(\"what is GenAI?\")\n",
    "print(type(result),len(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e412aa03-4e48-4a57-8721-fc6952fd0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GenAI\" stands for **Generative Artificial Intelligence**. \n",
      "\n",
      "Essentially, it's a branch of artificial intelligence (AI) focused on **creating new content** rather than just analyzing or interpreting existing data.  Here's a breakdown:\n",
      "\n",
      "**What does GenAI do?**\n",
      "\n",
      "* **Generates text:**  Writing stories, poems, articles, even scripts.\n",
      "* **Creates images and art:** Generating realistic paintings, sketches, photographs, and more.\n",
      "* **Composes music:** Creating original melodies, harmonies, and rhythms. \n",
      "* **Develops videos:** Generating short films, animation clips, or even entire movie sequences. \n",
      "* **Powers virtual assistants:** Enabling them to understand and respond to complex requests naturally.\n",
      "\n",
      "**Key Characteristics of GenAI:**\n",
      "\n",
      "* **Creativity:**  Unlike traditional AI, GenAI models are designed to generate entirely new content based on their training data. \n",
      "* **Learning from Data:** They learn patterns and relationships within massive datasets to create outputs that resemble human creativity.  \n",
      "* **Contextual Understanding:** Many GenAI models can understand context and adapt their output accordingly, making them much more versatile than previous AI models.\n",
      "\n",
      "**Popular Examples of GenAI:**\n",
      "\n",
      "* **DALL-E 2 & Midjourney:**  Generate images from text descriptions (text-to-image).\n",
      "* **ChatGPT & Bard:** Create human-like conversations and generate different creative text formats.\n",
      "* **GitHub Copilot:** Assists developers in writing code by generating suggestions, functions, and even whole lines of code.\n",
      "\n",
      "**The Future of GenAI:**\n",
      "\n",
      "GenAI holds immense potential for various fields, including: \n",
      "\n",
      "* **Creative industries:**  Writers, artists, musicians can leverage it to amplify their creativity.\n",
      "* **Marketing & Advertising:**  Creating targeted campaigns that resonate with specific audiences.\n",
      "* **Education:** Personalized learning experiences tailored to individual needs.\n",
      "* **Healthcare:** Generating medical reports and even assisting in diagnosing diseases.\n",
      "\n",
      "\n",
      "GenAI is still evolving rapidly, but its applications are vast and have the potential to revolutionize how we interact with technology and the world around us. \n",
      "\n",
      "\n",
      "\n",
      "Let me know if you'd like to explore any of these aspects further! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1ada841-4ebd-423b-a732-bab3bea655ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "print(\"Hello, world!\") \n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **`print()`:** This is a built-in function in Python that displays output on the console.\n",
      "* **`\"Hello, world!\"`:** This is a string of text enclosed in double quotes (`\"`). The `print()` function takes this string and outputs it to the screen.\n",
      "\n",
      "\n",
      "**How to run this program:**\n",
      "\n",
      "1. **Save the code:** Create a new file (e.g., hello.py) and paste the code into it.\n",
      "2. **Open a terminal/command prompt:** Navigate to where you saved the file using the `cd` command.\n",
      "3. **Run the script:** Type `python hello.py` and press Enter.\n",
      "\n",
      "You should see \"Hello, world!\" printed on your screen.\n",
      "\n",
      "\n",
      "Let me know if you'd like to explore more complex Python programs or learn about other ways to interact with the console! \n"
     ]
    }
   ],
   "source": [
    "result1= llm_obj.invoke(\"How to write Hello world program in Python?\")\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11dcb7b4-002d-4f5e-97ab-a91bb3d38d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model 'llama' not found (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m llm\u001b[38;5;241m=\u001b[39mOllamaLLM(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is AI?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:392\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    390\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 392\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    393\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    394\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    395\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    396\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    397\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    398\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    400\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    401\u001b[0m         )\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    404\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:791\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    790\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1002\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    988\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    989\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    990\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m         )\n\u001b[0;32m   1001\u001b[0m     ]\n\u001b[1;32m-> 1002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m   1003\u001b[0m         prompts,\n\u001b[0;32m   1004\u001b[0m         stop,\n\u001b[0;32m   1005\u001b[0m         run_managers,\n\u001b[0;32m   1006\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1010\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1011\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m   1012\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[0;32m   1020\u001b[0m     ]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:817\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    808\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    814\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 817\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    818\u001b[0m                 prompts,\n\u001b[0;32m    819\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    820\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    821\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    822\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    823\u001b[0m             )\n\u001b[0;32m    824\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    825\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    826\u001b[0m         )\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_ollama\\llms.py:459\u001b[0m, in \u001b[0;36mOllamaLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 459\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_with_aggregation(\n\u001b[0;32m    460\u001b[0m         prompt,\n\u001b[0;32m    461\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    462\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    463\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    465\u001b[0m     )\n\u001b[0;32m    466\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_ollama\\llms.py:418\u001b[0m, in \u001b[0;36mOllamaLLM._stream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    417\u001b[0m thinking_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 418\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinking\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_ollama\\llms.py:362\u001b[0m, in \u001b[0;36mOllamaLLM._create_generate_stream\u001b[1;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    357\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    358\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    360\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client:\n\u001b[1;32m--> 362\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_params(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ollama\\_client.py:179\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    178\u001b[0m   e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 179\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[0;32m    182\u001b[0m   part \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "\u001b[1;31mResponseError\u001b[0m: model 'llama' not found (status code: 404)"
     ]
    }
   ],
   "source": [
    "llm=OllamaLLM(model=\"llama\")\n",
    "#llm.invoke(\"what is AI?\")\n",
    "# ResponseError: model 'llama' not found (status code: 404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a3ff4-c997-4878-a8ed-d4f1c1f67ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading from various sources - text file, pdf, web, wikipedia... // loader class\n",
    "\n",
    "document loading\n",
    "-------->langchain_community.document_loaders\n",
    "                                        |------> TextLoader  |---> PDFLoader    <classes>\n",
    "1. using document loader class -> Get the doc\n",
    "2. doc-->metadata+ actual data\n",
    "                    ==========\n",
    "                       |--> page_content:<actual_data>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c77be4eb-987a-471c-a300-2107854c1faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x1ee55564ad0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "TextLoader('my_docs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7fbabb4a-7c7d-4f01-a616-87112b80b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'my_docs.txt'}, page_content=\"LangChain is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDevelopment: Build your applications using LangChain's open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\\nProductionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\\nDeployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\")]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = TextLoader('my_docs.txt')   #  input file --> Reg. file/ ASCII/TextFile\n",
    "loader_obj.load()  # --> doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ab05c12-b034-4d1f-9a41-d5c57d8e32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader_obj = TextLoader('my_docs.txt')  \n",
    "Text_doc= loader_obj.load()  \n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader_obj=PyPDFLoader('attention.pdf')\n",
    "pdf_docs=loader_obj.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c10cf06-9865-4944-b6a8-026a11ae834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1\n"
     ]
    }
   ],
   "source": [
    "print(type(Text_doc), len(Text_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "508b67e5-6e59-4ff9-9247-dc7567c6381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n"
     ]
    }
   ],
   "source": [
    "print(type(pdf_docs),len(pdf_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28513a07-9cfb-4332-ab9c-4b1f14981f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181afb7-914a-4bcf-8e75-b972f8566287",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests - GET \n",
    "bs4 - extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33064d-5321-4200-89d6-23bf2d0379f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.get('url') ---> return status code --> 200 ; okay ; != 200  -> Failed\n",
    "\n",
    "requests.get('url')--> returncode.headers-> {} -\n",
    "                    |---> returncode.text ---> Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a45d5463-0878-48f3-b472-85c488584855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get('http://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "077ed8dc-c7f7-40fe-83e7-576a48cee15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Mon, 12 Jan 2026 11:03:14 GMT', 'Expires': '-1', 'Cache-Control': 'private, max-age=0', 'Content-Type': 'text/html; charset=ISO-8859-1', 'Content-Security-Policy-Report-Only': \"object-src 'none';base-uri 'self';script-src 'nonce-dWxb2iOZGz2akSZkm3qP5A' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http:;report-uri https://csp.withgoogle.com/csp/gws/other-hp\", 'P3P': 'CP=\"This is not a P3P policy! See g.co/p3phelp for more info.\"', 'Content-Encoding': 'gzip', 'Server': 'gws', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'Set-Cookie': '__Secure-STRP=AD6DogsCESHFD5QgCtGpvFS80-iurTG88u6GWAqHmgKPabwdx3Y5FfTLxXnaNe5gGOpamAa6in7aa9WjrPRxEk-dNHYlO1o9z5Yo; expires=Mon, 12-Jan-2026 11:08:14 GMT; path=/; domain=.google.com; Secure; SameSite=strict, AEC=AaJma5vQuRpMqxyaywQzre6oUyVT0DTwqRlYFjS215nrButxzTOd3PRFdA; expires=Sat, 11-Jul-2026 11:03:14 GMT; path=/; domain=.google.com; Secure; HttpOnly; SameSite=lax, NID=528=B_jq_X4RTl-33C4hravo-tk4oyKgCpOhqu7ekJiRaF4xE90fNGmi5ypEUGKCmp_vSx086I8VBZH7ycBv9A-CHfGzL7fhNGLem_XID9kWczb0TF5sLT93oE9kGTWh-wIOAxq0qV047k9xOKXqxeKIelgEj-6ezvJuqBNQ_kQd_mWeTPTQSnlfIqSoKw3EC-vVUOFCkaCttx9iIVpJH0ECN1lco64KUgrwFg; expires=Tue, 14-Jul-2026 11:03:14 GMT; path=/; domain=.google.com; HttpOnly', 'Transfer-Encoding': 'chunked'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r= requests.get('http://www.google.com')\n",
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d1ae1cb5-9a36-43bc-a11b-a8ae3576bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"en-IN\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"dWxb2iOZGz2akSZkm3qP5A\">(function(){var _g={kEI:\\'8tRkabyzMer8kPIP34GliQ0\\',kEXPI:\\'0,203004,1101199,2949954,425602,270475,30675,5231286,257,36811675,25381059,65176,30628,9138,11153,50098,14067,15097,8157,3292,34513,28334,48904,30410,7714,33385,3050,2,875,7,25160,2884,19843,46337,21899,4372,6292,6437,9742,2646,103,4,1,13145,10993,14505,1198,185,2,1,1515,3355,2,194,5814,2,4205,3,10939,775,4384,2,874,24,1653,554,5089,19,3008,22,773,4081,4,5386,13783,2386,2,1,9730,211,1039,1034,4303,311,534,846,1200,2,12,16,415,1,1129,3,2842,9,27,8,3055,1010,1747,4,4636,10557,4,696,1475,45,2,9,4,12,241,296,5,1113,389,4,299,2264,84,5,5568,298,5201,1055,2997,1275,7,1784,7,997,46,2,296,1622,516,6032,1251,4,93,2,2559,2,5724,9,602,59,37,1553,4,1882,4,1,3,2,1,1493,3458,603,3522,8,14,88,235,3,635,1,2,245,476,2,2141,3,2788,49,10,215,441,1805,191,4,28,1900,2,1636,544,4,1681,861,59,732,3,562,5,97,187,259,89,514,1243,5,179,80,5,197,1921,445,19,295,1245,4,235,136,14,1039,223,377,4,336,356,3,333,1671,5,40,420,108,6,154,5,149,1770,82,24,975,2186,141,398,4,75,1975,111,153,107,5,4,965,4,322,1737,42,3,2,1477,491,4,664,625,489,4,32,4,847,1154,12,690,4,40,4,862,7,1093,12,556,1,5,16,66,257,1,1816,536,375,5,1238,247,444,79,708,4,2,2,3,2,1,823,236,56,3,2,2,2,147,4,1940,4,61,945,48,4,32,158,1,242,790,379,3,2,1,328,1,1091,1,836,64,63,102,1118,1,1,2,31,60,2,560,661,4,730,52,4,38,1491,496,751,725,389,176,545,193,241,4,746,4,92,1374,832,123,8,45,60,434,278,788,801,125,464,140,219,2,2191,261,451,380,3,2,2,2,86,3,2,2,2,51,3,2,2,2,1333,1863,474,2549,3,873,444,1604,4,239,357,442,4,20592414,416080,5,2253,739,4,2960,3,2022,1215,5254,2,1562,3,2687,3,9181,1303,1696,1194,3,739,6,1156,3,5578,2,440,363,275,282,3,6493264,2533,2,1119,1343,3840308,11901908,2907,4857,1,77248,6,117056,4749756\\',kBL:\\'vhrl\\',kOPI:89978449};(function(){var a;((a=window.google)==null?0:a.stvsc)?google.kEI=_g.kEI:window.google=_g;}).call(this);})();(function(){google.sn=\\'webhp\\';google.kHL=\\'en-IN\\';google.rdn=false;})();(function(){\\nvar g=this||self;function k(){return window.google&&window.google.kOPI||null};var l,m=[];function n(a){for(var b;a&&(!a.getAttribute||!(b=a.getAttribute(\"eid\")));)a=a.parentNode;return b||l}function p(a){for(var b=null;a&&(!a.getAttribute||!(b=a.getAttribute(\"leid\")));)a=a.parentNode;return b}function q(a){/^http:/i.test(a)&&window.location.protocol===\"https:\"&&(google.ml&&google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a}\\nfunction r(a,b,d,c,h){var e=\"\";b.search(\"&ei=\")===-1&&(e=\"&ei=\"+n(c),b.search(\"&lei=\")===-1&&(c=p(c))&&(e+=\"&lei=\"+c));var f=b.search(\"&cshid=\")===-1&&a!==\"slh\";c=\"&zx=\"+Date.now().toString();g._cshid&&f&&(c+=\"&cshid=\"+g._cshid);(d=d())&&(c+=\"&opi=\"+d);return\"/\"+(h||\"gen_204\")+\"?atyp=i&ct=\"+String(a)+\"&cad=\"+(b+e+c)};l=google.kEI;google.getEI=n;google.getLEI=p;google.ml=function(){return null};google.log=function(a,b,d,c,h,e){e=e===void 0?k:e;d||(d=r(a,b,e,c,h));if(d=q(d)){a=new Image;var f=m.length;m[f]=a;a.onerror=a.onload=a.onabort=function(){delete m[f]};a.src=d}};google.logUrl=function(a,b){b=b===void 0?k:b;return r(\"\",a,b)};}).call(this);(function(){google.y={};google.sy={};function e(a,b,c){if(a)var d=a.id;else{do d=Math.random();while(c[d])}c[d]=[a,b]}var f;(f=google).x||(f.x=function(a,b){e(a,b,google.y)});var g;(g=google).sx||(g.sx=function(a,b){e(a,b,google.sy)});google.lm=[];var h;(h=google).plm||(h.plm=function(a){google.lm.push.apply(google.lm,a)});google.lq=[];var k;(k=google).load||(k.load=function(a,b,c){google.lq.push([[a],b,c])});var l;(l=google).loadAll||(l.loadAll=function(a,b){google.lq.push([a,b])});google.bx=!1;var m;(m=google).lx||(m.lx=function(){});var n=[],p;(p=google).fce||(p.fce=function(a,b,c,d){n.push([a,b,c,d])});google.qce=n;google.adl=[];}).call(this);google.f={};(function(){\\ndocument.documentElement.addEventListener(\"submit\",function(b){var a;if(a=b.target){var c=a.getAttribute(\"data-submitfalse\");a=c===\"1\"||c===\"q\"&&!a.elements.q.value?!0:!1}else a=!1;a&&(b.preventDefault(),b.stopPropagation())},!0);document.documentElement.addEventListener(\"click\",function(b){var a;a:{for(a=b.target;a&&a!==document.documentElement;a=a.parentElement)if(a.tagName===\"A\"){a=a.getAttribute(\"data-nohref\")===\"1\";break a}a=!1}a&&b.preventDefault()},!0);}).call(this);</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}\\n</style><style>body,td,a,p,.h{font-family:sans-serif}body{margin:0;overflow-y:scroll}#gog{padding:3px 8px 0}td{line-height:.8em}.gac_m td{line-height:17px}form{margin-bottom:20px}.h{color:#1967d2}em{font-weight:bold;font-style:normal}.lst{height:25px;width:496px}.gsfi,.lst{font:18px sans-serif}.gsfs{font:17px sans-serif}.ds{display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px}input{font-family:inherit}body{background:#fff;color:#1f1f1f}a{color:#681da8;text-decoration:none}a:hover,a:active{text-decoration:underline}.fl a{color:#1967d2}a:visited{color:#681da8}.sblc{padding-top:5px}.sblc a{display:block;margin:2px 0;margin-left:13px;font-size:11px}.lsbb{background:#ecedee;border:solid 1px;border-color:#d2d2d2 #70757a #70757a #d2d2d2;height:30px}.lsbb{display:block}#WqQANb a{display:inline-block;margin:0 12px}.lsb{background:url(/images/nav_logo229.png) 0 -261px repeat-x;color:#1f1f1f;border:none;cursor:pointer;height:30px;margin:0;outline:0;font:15px sans-serif;vertical-align:top}.lsb:active{background:#dadce0}.lst:focus{outline:none}</style><script nonce=\"dWxb2iOZGz2akSZkm3qP5A\">(function(){window.google.erd={jsr:1,bv:2357,de:true,dpf:\\'otQ7OFE4CZ1-O2RuiJYAprPjS49uoo1882V-45YHyNk\\'};\\nvar g=this||self;var k,l=(k=g.mei)!=null?k:1,m,p=(m=g.diel)!=null?m:0,q,r=(q=g.sdo)!=null?q:!0,t=0,u,w=google.erd,x=w.jsr;google.ml=function(a,b,d,n,e){e=e===void 0?2:e;b&&(u=a&&a.message);d===void 0&&(d={});d.cad=\"ple_\"+google.ple+\".aple_\"+google.aple;if(google.dl)return google.dl(a,e,d,!0),null;b=d;if(x<0){window.console&&console.error(a,b);if(x===-2)throw a;b=!1}else b=!a||!a.message||a.message===\"Error loading script\"||t>=l&&!n?!1:!0;if(!b)return null;t++;d=d||{};b=encodeURIComponent;var c=\"/gen_204?atyp=i&ei=\"+b(google.kEI);google.kEXPI&&(c+=\"&jexpid=\"+b(google.kEXPI));c+=\"&srcpg=\"+b(google.sn)+\"&jsr=\"+b(w.jsr)+\\n\"&bver=\"+b(w.bv);w.dpf&&(c+=\"&dpf=\"+b(w.dpf));var f=a.lineNumber;f!==void 0&&(c+=\"&line=\"+f);var h=a.fileName;h&&(h.indexOf(\"-extension:/\")>0&&(e=3),c+=\"&script=\"+b(h),f&&h===window.location.href&&(f=document.documentElement.outerHTML.split(\"\\\\n\")[f],c+=\"&cad=\"+b(f?f.substring(0,300):\"No script found.\")));google.ple&&google.ple===1&&(e=2);c+=\"&jsel=\"+e;for(var v in d)c+=\"&\",c+=b(v),c+=\"=\",c+=b(d[v]);c=c+\"&emsg=\"+b(a.name+\": \"+a.message);c=c+\"&jsst=\"+b(a.stack||\"N/A\");c.length>=12288&&(c=c.substring(0,12288));a=c;n||google.log(0,\"\",a);return a};window.onerror=function(a,b,d,n,e){u!==a&&(a=e instanceof Error?e:Error(a),d===void 0||\"lineNumber\"in a||(a.lineNumber=d),b===void 0||\"fileName\"in a||(a.fileName=b),google.ml(a,!1,void 0,!1,a.name===\"SyntaxError\"||a.message.substring(0,11)===\"SyntaxError\"||a.message.indexOf(\"Script error\")!==-1?3:p));u=null;r&&t>=l&&(window.onerror=null)};})();</script></head><body bgcolor=\"#fff\"><script nonce=\"dWxb2iOZGz2akSZkm3qP5A\">(function(){var src=\\'/images/nav_logo229.png\\';var iesg=false;document.body.onload = function(){window.n && window.n();if (document.images){new Image().src=src;}\\nif (!iesg){document.f&&document.f.q.focus();document.gbqf&&document.gbqf.q.focus();}\\n}\\n})();</script><div id=\"mngb\"><div id=gbar><nobr><b class=gb1>Search</b> <a class=gb1 href=\"https://www.google.com/imghp?hl=en&tab=wi\">Images</a> <a class=gb1 href=\"http://maps.google.co.in/maps?hl=en&tab=wl\">Maps</a> <a class=gb1 href=\"https://play.google.com/?hl=en&tab=w8\">Play</a> <a class=gb1 href=\"https://www.youtube.com/?tab=w1\">YouTube</a> <a class=gb1 href=\"https://news.google.com/?tab=wn\">News</a> <a class=gb1 href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a> <a class=gb1 href=\"https://drive.google.com/?tab=wo\">Drive</a> <a class=gb1 style=\"text-decoration:none\" href=\"https://www.google.co.in/intl/en/about/products?tab=wh\"><u>More</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a href=\"http://www.google.co.in/history/optout?hl=en\" class=gb4>Web History</a> | <a  href=\"/preferences?hl=en\" class=gb4>Settings</a> | <a target=_top id=gb_70 href=\"https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=http://www.google.com/&ec=GAZAAQ\" class=gb4>Sign in</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div></div><center><br clear=\"all\" id=\"lgpd\"><div><img alt=\"Google\" height=\"92\" src=\"/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\" style=\"padding:28px 0 14px\" width=\"272\" id=\"hplogo\"><br><br></div><form action=\"/search\" name=\"f\"><table cellpadding=\"0\" cellspacing=\"0\"><tr valign=\"top\"><td width=\"25%\">&nbsp;</td><td align=\"center\" nowrap=\"\"><input name=\"ie\" value=\"ISO-8859-1\" type=\"hidden\"><input value=\"en-IN\" name=\"hl\" type=\"hidden\"><input name=\"source\" type=\"hidden\" value=\"hp\"><input name=\"biw\" type=\"hidden\"><input name=\"bih\" type=\"hidden\"><div class=\"ds\" style=\"height:32px;margin:4px 0\"><input class=\"lst\" style=\"margin:0;padding:5px 8px 0 6px;vertical-align:top;color:#1f1f1f\" autocomplete=\"off\" value=\"\" title=\"Google Search\" maxlength=\"2048\" name=\"q\" size=\"57\"></div><br style=\"line-height:0\"><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" value=\"Google Search\" name=\"btnG\" type=\"submit\"></span></span><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" id=\"tsuid_8tRkabyzMer8kPIP34GliQ0_1\" value=\"I\\'m Feeling Lucky\" name=\"btnI\" type=\"submit\"><script nonce=\"dWxb2iOZGz2akSZkm3qP5A\">(function(){var id=\\'tsuid_8tRkabyzMer8kPIP34GliQ0_1\\';document.getElementById(id).onclick = function(){if (this.form.q.value){this.checked = 1;if (this.form.iflsig)this.form.iflsig.disabled = false;}\\nelse top.location=\\'/doodles/\\';};})();</script><input value=\"AFdpzrgAAAAAaWTjAir88CJx66MRZUpvNfY00ugrXsYe\" name=\"iflsig\" type=\"hidden\"></span></span></td><td class=\"fl sblc\" align=\"left\" nowrap=\"\" width=\"25%\"><a href=\"/advanced_search?hl=en-IN&amp;authuser=0\">Advanced search</a></td></tr></table><input id=\"gbv\" name=\"gbv\" type=\"hidden\" value=\"1\"><script nonce=\"dWxb2iOZGz2akSZkm3qP5A\">(function(){var a,b=\"1\";if(document&&document.getElementById)if(typeof XMLHttpRequest!=\"undefined\")b=\"2\";else if(typeof ActiveXObject!=\"undefined\"){var c,d,e=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"];for(c=0;d=e[c++];)try{new ActiveXObject(d),b=\"2\"}catch(h){}}a=b;if(a==\"2\"&&location.search.indexOf(\"&gbv=2\")==-1){var f=google.gbvu,g=document.getElementById(\"gbv\");g&&(g.value=a);f&&window.setTimeout(function(){location.href=f},0)};}).call(this);</script></form><div style=\"font-size:83%;min-height:3.5em\"><br><div id=\"gws-output-pages-elements-homepage_additional_languages__als\"><style>#gws-output-pages-elements-homepage_additional_languages__als{font-size:small;margin-bottom:24px}#SIvCob{color:#545454;display:inline-block;line-height:28px;}#SIvCob a{}.H6sW5{display:inline-block;margin:0 2px;white-space:nowrap}.z4hgWe{display:inline-block;margin:0 2px}</style><div id=\"SIvCob\">Google offered in:  <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=hi&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAY\">&#2361;&#2367;&#2344;&#2381;&#2342;&#2368;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=bn&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAc\">&#2476;&#2494;&#2434;&#2482;&#2494;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=te&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAg\">&#3108;&#3142;&#3122;&#3137;&#3095;&#3137;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=mr&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAk\">&#2350;&#2352;&#2366;&#2336;&#2368;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=ta&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAo\">&#2980;&#2990;&#3007;&#2996;&#3021;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=gu&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAs\">&#2711;&#2753;&#2716;&#2736;&#2750;&#2724;&#2752;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=kn&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCAw\">&#3221;&#3240;&#3277;&#3240;&#3233;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=ml&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCA0\">&#3374;&#3378;&#3375;&#3390;&#3379;&#3330;</a>    <a href=\"http://www.google.com/setprefs?sig=0_Fw4_8435vKUT0n5_r_B-YjV9MVY%3D&amp;hl=pa&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwi89NeS7YWSAxVqPkQIHd9AKdEQ2ZgBCA4\">&#2602;&#2672;&#2588;&#2622;&#2604;&#2624;</a>  </div></div></div><span id=\"footer\"><div style=\"font-size:10pt\"><div style=\"margin:19px auto;text-align:center\" id=\"WqQANb\"><a href=\"/intl/en/ads/\">Advertising</a><a href=\"http://www.google.co.in/services/\">Business Solutions</a><a href=\"/intl/en/about.html\">About Google</a><a href=\"http://www.google.com/setprefdomain?prefdom=IN&amp;prev=http://www.google.co.in/&amp;sig=K_AzCBSvKtpvsuIl6X6NWDTz7tK30%3D\">Google.co.in</a></div></div><p style=\"font-size:8pt;color:#636363\">&copy; 2026 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p></span></center><script nonce=\"dWxb2iOZGz2akSZkm3qP5A\">(function(){window.google.cdo={height:757,width:1440};(function(){var a=window.innerWidth,b=window.innerHeight;if(!a||!b){var c=window.document,d=c.compatMode==\"CSS1Compat\"?c.documentElement:c.body;a=d.clientWidth;b=d.clientHeight}if(a&&b&&(a!=google.cdo.width||b!=google.cdo.height)){var e=google,f=e.log,g=\"/client_204?&atyp=i&biw=\"+a+\"&bih=\"+b+\"&ei=\"+google.kEI,h=\"\",k=window.google&&window.google.kOPI||null;k&&(h+=\"&opi=\"+k);f.call(e,\"\",\"\",g+h)};}).call(this);})();(function(){google.xjs={basecomb:\\'/xjs/_/js/k\\\\x3dxjs.hp.en.vN14ppHXl7Y.es5.O/ck\\\\x3dxjs.hp.68TFQL-V7tE.L.X.O/am\\\\x3dgAQAAAAAAAACAAAAAAAAAAAAAAAAAAAAAAAEAAAQEAgAAAAAAAAAAAAAAAAgAAAAAABEMAAAJACSAAAAAAAAAQBAAAAAAAAgAAAIQAAAAPEdAQAAAIAAWAQAAAAAAC8/d\\\\x3d1/ed\\\\x3d1/dg\\\\x3d0/ujg\\\\x3d1/rs\\\\x3dACT90oHuhHSdJZqIwJkGDVhLkdPnftOCAA\\',basecss:\\'/xjs/_/ss/k\\\\x3dxjs.hp.68TFQL-V7tE.L.X.O/am\\\\x3dgAQAAAAAAAACAAAAAAAAAAAAAAAAAAAAAAAEAAAQAAgAAAAAAAAAAAAAAAAAAAAAAAAEAAAAJACSAAAAAAAAAQBAAAAAAAAgAAAIQA/rs\\\\x3dACT90oGQliqt5SJPIJYW-V66PlvvsEx6OQ\\',basejs:\\'/xjs/_/js/k\\\\x3dxjs.hp.en.vN14ppHXl7Y.es5.O/am\\\\x3dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAgAAAAAABAMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEdAQAAAIAAWAQAAAAAAC8/dg\\\\x3d0/rs\\\\x3dACT90oHUCAX6ryHXKPOt0pqtriDqrJdf-g\\',excm:[]};})();(function(){var u=\\'/xjs/_/js/k\\\\x3dxjs.hp.en.vN14ppHXl7Y.es5.O/am\\\\x3dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAgAAAAAABAMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPEdAQAAAIAAWAQAAAAAAC8/d\\\\x3d1/ed\\\\x3d1/dg\\\\x3d4/rs\\\\x3dACT90oHUCAX6ryHXKPOt0pqtriDqrJdf-g/m\\\\x3dsb_he,d\\';var st=1;var amd=1000;var mmd=0;var pop=true;var povp=false;var fp=\\'\\';var ecb=false;var cst=false;var pxp=false;\\nvar f=this||self;function g(){var a=google.ia&&google.ia.r.B2Jtyd;return a&&[1,5,6].indexOf(a.m)>=0&&a.cbfd&&a.cbvi?a:void 0};function h(a){var b=document.createElement(\"link\");b.as=\"script\";b.href=a;b.rel=\"preload\";document.body.appendChild(b)}function k(){var a=[l];google.dp||(a.forEach(h),google.dp=!0)};google.ps=google.ps||[];function m(a){var b=l,c=function(){};google.lx=google.stvsc?c:function(){n(b,a);google.lx=c};google.bx||google.lx()}function p(a,b){b&&(a.src=b);fp&&google.caft&&google.caft(function(){a.fetchPriority=fp});var c=a.onload;a.onload=function(e){c&&c(e);google.ps=google.ps.filter(function(d){return a.src!==d})};google.ps.push(a.src);document.body.appendChild(a)}function q(a,b,c){b?requestAnimationFrame(function(){p(a,c)}):p(a,c)}google.as=p;function n(a,b){google.tick&&google.tick(\"load\",\"xjsls\");var c=document.createElement(\"script\");c.onerror=function(){google.ple=1};c.onload=function(){google.ple=0};google.xjsus=void 0;q(c,b,a);google.aple=-1;google.dp=!0};function r(){for(var a=document.getElementsByTagName(\"img\"),b=0,c=a.length;b<c;b++){var e=a[b],d;if(d=e.hasAttribute(\"data-lzy_\")&&Number(e.getAttribute(\"data-atf\"))&1)d=e.getAttribute(\"jscontroller\"),d=!((d===\"UBXHI\"||d===\"R3fhkb\"||d===\"TSZEqd\")&&e.hasAttribute(\"data-src\"));if(d)return!0}return!1};var l,t,w,x,y,z,A,B,C,D,E=\"\";function F(){l=pxp&&google.xjsup||u;var a=l.match(\"/cb=(loaded_h_\\\\\\\\d+)\");a&&a[1]&&(E=a[1]);google.xjsu=l;f._F_jsUrl=l;z=function(c){m(c)};t=!1;w=(st===1||st===3)&&!!google.caft&&!r();x=g();y=!E&&(st===2||st===3)&&!!x&&!r();if(E){var b=(st===2||st===3)&&!!x;f[E]=function(c){var e=!1,d=function(){e||(e=!0,cst?setTimeout(function(){return void c.call(window,window._)},0):c.call(window,window._))};b&&google.ia.adls?(x.cbvi.push(function(){delete google.ia.adls}),x.cbvi.push(d),setTimeout(d,mmd)):d()}}A=\\npop;B=povp;C=A&&document.prerendering||B&&document.hidden;D=B?\"visibilitychange\":\"prerenderingchange\"}function G(a){t||w||y||C||(z(a),t=!0)}\\nsetTimeout(function(){google.tick&&google.tick(\"load\",\"xjspls\");F();if(w||y||C){if(w){var a=function(){w=!1;G()};google.caft(a);setTimeout(a,amd)}y&&(a=function(){y=!1;G()},x.cbvi.push(a),setTimeout(a,mmd));if(C){var b=function(){(B?document.hidden:document.prerendering)||(C=!1,G(!B&&!1),document.removeEventListener(D,b))};document.addEventListener(D,b,{passive:!0})}t||k()}else z()},0);})();window._ = window._ || {};window._DumpException = _._DumpException = function(e){throw e;};window._s = window._s || {};_s._DumpException = _._DumpException;window._qs = window._qs || {};_qs._DumpException = _._DumpException;window.loaded_h_0 = function(cb){cb.call(window,window._);};(function(){var t=[1152,0,32,0,0,0,0,67108869,2072,0,16,134217728,791019520,180424768,537018440,67141668,16811032,65536,0,33554440,64,292804,134217728,71200,0,188];window._F_toggles = window._xjs_toggles = t;})();window._F_installCss = window._F_installCss || function(css){};(function(){var pmc=\\'{\\\\x22d\\\\x22:{},\\\\x22sb_he\\\\x22:{\\\\x22client\\\\x22:\\\\x22heirloom-hp\\\\x22,\\\\x22dh\\\\x22:true,\\\\x22ds\\\\x22:\\\\x22\\\\x22,\\\\x22host\\\\x22:\\\\x22google.com\\\\x22,\\\\x22jsonp\\\\x22:true,\\\\x22msgs\\\\x22:{\\\\x22cibl\\\\x22:\\\\x22Clear Search\\\\x22,\\\\x22dym\\\\x22:\\\\x22Did you mean:\\\\x22,\\\\x22lcky\\\\x22:\\\\x22I\\\\\\\\u0026#39;m Feeling Lucky\\\\x22,\\\\x22lml\\\\x22:\\\\x22Learn more\\\\x22,\\\\x22psrc\\\\x22:\\\\x22This search was removed from your \\\\\\\\u003Ca href\\\\x3d\\\\\\\\\\\\x22/history\\\\\\\\\\\\x22\\\\\\\\u003EWeb History\\\\\\\\u003C/a\\\\\\\\u003E\\\\x22,\\\\x22psrl\\\\x22:\\\\x22Remove\\\\x22,\\\\x22sbit\\\\x22:\\\\x22Search by image\\\\x22,\\\\x22srch\\\\x22:\\\\x22Google Search\\\\x22},\\\\x22ovr\\\\x22:{},\\\\x22pq\\\\x22:\\\\x22\\\\x22,\\\\x22rfs\\\\x22:[],\\\\x22stok\\\\x22:\\\\x22J8pVo0PDjXF9cUO6u3j560bcENs\\\\x22}}\\';google.pmc=JSON.parse(pmc);})();</script></body></html>'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f71f9b72-86f3-4350-a3bd-4b346b060a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 19706\n"
     ]
    }
   ],
   "source": [
    "google_web=r.text\n",
    "print(type(google_web),len(google_web))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea71d10c-ef46-46e8-b654-de2d1dcb312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For testing\n",
    "with open('test1.html','w') as wobj:\n",
    "    wobj.write(google_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b872bc-9749-4859-b441-014d0d6227a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "#  bs4\n",
    "#   |\n",
    "#  BeautifulSoup(webpagecontent)--> bs4_obj\n",
    "# bs4_obj.find(<htmltag>) => single str\n",
    "(or)\n",
    "# bs4_obj.find_all(<html_tag>) => data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "893d42e8-dc0b-4987-a7b5-ebaa502fc49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Google</title>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "web_obj=bs4.BeautifulSoup(google_web)\n",
    "web_obj.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c41633d-0c2a-4f55-bf35-e648b83c849e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Google</title>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('title')   # same as web_obj.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ff968d93-5c9a-4fb7-a78e-77f5533b6955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p style=\"font-size:8pt;color:#636363\">© 2026 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7fbced0-4869-474b-b210-0e17df206095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'font-size:8pt;color:#636363'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('p').get('style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ada09f2-5914-47f2-aad3-498600e2ad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/imghp?hl=en&tab=wi'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_obj.find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9b92c999-14c1-4ffd-a8da-de7adf151722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs from google.com\n",
    "# Listof rpm file from yum.oracle.com/OL9\n",
    "r=requests.get('https://www.google.com')\n",
    "webpage=r.text\n",
    "gpage=bs4.BeautifulSoup(webpage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4e542343-3476-4fb6-bfc1-d142786663ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/imghp?hl=en&tab=wi\n",
      "https://maps.google.co.in/maps?hl=en&tab=wl\n",
      "https://play.google.com/?hl=en&tab=w8\n",
      "https://www.youtube.com/?tab=w1\n",
      "https://news.google.com/?tab=wn\n",
      "https://mail.google.com/mail/?tab=wm\n",
      "https://drive.google.com/?tab=wo\n",
      "https://www.google.co.in/intl/en/about/products?tab=wh\n",
      "http://www.google.co.in/history/optout?hl=en\n",
      "/preferences?hl=en\n",
      "https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/&ec=GAZAAQ\n",
      "/advanced_search?hl=en-IN&authuser=0\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=hi&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAY\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=bn&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAc\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=te&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAg\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=mr&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAk\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=ta&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAo\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=gu&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAs\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=kn&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCAw\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=ml&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCA0\n",
      "https://www.google.com/setprefs?sig=0_XmMtEbfzA0YV2bnETHezwjmTKc4%3D&hl=pa&source=homepage&sa=X&ved=0ahUKEwjNsJmR8IWSAxVbEEQIHcVDAUIQ2ZgBCA4\n",
      "/intl/en/ads/\n",
      "http://www.google.co.in/services/\n",
      "/intl/en/about.html\n",
      "https://www.google.com/setprefdomain?prefdom=IN&prev=https://www.google.co.in/&sig=K_KRIEj25Fvad7L8-315KcQvFoqEQ%3D\n",
      "/intl/en/policies/privacy/\n",
      "/intl/en/policies/terms/\n"
     ]
    }
   ],
   "source": [
    "L=gpage.find_all('a')\n",
    "for var in L:\n",
    "    print(var.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8b07e-cb6e-4f06-a4aa-d2ca3f8f8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3107c5c1-4e77-4819-8f8b-b06fb77fe901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.google.com', 'title': 'Google', 'language': 'en-IN'}, page_content='GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in\\xa0Advanced searchGoogle offered in:  हिन्दी বাংলা తెలుగు मराठी தமிழ் ગુજરાતી ಕನ್ನಡ മലയാളം ਪੰਜਾਬੀ AdvertisingBusiness SolutionsAbout GoogleGoogle.co.in© 2026 - Privacy - Terms')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "# From Single URL\n",
    "web_loader= WebBaseLoader(web_path='https://www.google.com')\n",
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2c42e3e8-221d-4dc6-a10d-106d1b3ae81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.google.com', 'title': 'Google', 'language': 'en-IN'}, page_content='GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in\\xa0Advanced searchGoogle offered in:  हिन्दी বাংলা తెలుగు मराठी தமிழ் ગુજરાતી ಕನ್ನಡ മലയാളം ਪੰਜਾਬੀ AdvertisingBusiness SolutionsAbout GoogleGoogle.co.in© 2026 - Privacy - Terms'),\n",
       " Document(metadata={'source': 'http://www.python.org', 'title': 'Welcome to Python.org', 'description': 'The official home of the Python Programming Language', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to Python.org\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotice: While JavaScript is not essential for this website, your interaction with the content will be limited. Please turn JavaScript on for the full experience. \\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n▼ Close\\n                \\n\\n\\nPython\\n\\n\\nPSF\\n\\n\\nDocs\\n\\n\\nPyPI\\n\\n\\nJobs\\n\\n\\nCommunity\\n\\n\\n\\n▲ The Python Network\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\n≡ Menu\\n\\n\\nSearch This Site\\n\\n\\n                                    GO\\n                                \\n\\n\\n\\n\\nA A\\n\\nSmaller\\nLarger\\nReset\\n\\n\\n\\n\\n\\n\\nSocialize\\n\\nLinkedIn\\nMastodon\\nChat on IRC\\nTwitter\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\nApplications\\nQuotes\\nGetting Started\\nHelp\\nPython Brochure\\n\\n\\n\\nDownloads\\n\\nAll releases\\nSource code\\nWindows\\nmacOS\\nAndroid\\nOther Platforms\\nLicense\\nAlternative Implementations\\n\\n\\n\\nDocumentation\\n\\nDocs\\nAudio/Visual Talks\\nBeginner\\'s Guide\\nFAQ\\nNon-English Docs\\nPEP Index\\nPython Books\\nPython Essays\\n\\n\\n\\nCommunity\\n\\nDiversity\\nMailing Lists\\nIRC\\nForums\\nPSF Annual Impact Report\\nPython Conferences\\nSpecial Interest Groups\\nPython Logo\\nPython Wiki\\nCode of Conduct\\nCommunity Awards\\nGet Involved\\nShared Stories\\n\\n\\n\\nSuccess Stories\\n\\nArts\\nBusiness\\nEducation\\nEngineering\\nGovernment\\nScientific\\nSoftware Development\\n\\n\\n\\nNews\\n\\nPython News\\nPSF Newsletter\\nPSF News\\nPyCon US News\\nNews from the Community\\n\\n\\n\\nEvents\\n\\nPython Events\\nUser Group Events\\nPython Events Archive\\nUser Group Events Archive\\nSubmit an Event\\n\\n\\n\\n\\n \\n\\n\\n\\n>_\\n                        Launch Interactive Shell\\n\\n\\n\\n\\n\\n# Python 3: Fibonacci series up to n\\r\\n>>> def fib(n):\\r\\n>>>     a, b = 0, 1\\r\\n>>>     while a < n:\\r\\n>>>         print(a, end=\\' \\')\\r\\n>>>         a, b = b, a+b\\r\\n>>>     print()\\r\\n>>> fib(1000)\\r\\n0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987\\nFunctions Defined\\nThe core of extensible programming is defining functions. Python allows mandatory and optional arguments, keyword arguments, and even arbitrary argument lists. More about defining functions in Python\\xa03\\n\\n\\n# Python 3: List comprehensions\\r\\n>>> fruits = [\\'Banana\\', \\'Apple\\', \\'Lime\\']\\r\\n>>> loud_fruits = [fruit.upper() for fruit in fruits]\\r\\n>>> print(loud_fruits)\\r\\n[\\'BANANA\\', \\'APPLE\\', \\'LIME\\']\\r\\n\\r\\n# List and the enumerate function\\r\\n>>> list(enumerate(fruits))\\r\\n[(0, \\'Banana\\'), (1, \\'Apple\\'), (2, \\'Lime\\')]\\nCompound Data Types\\nLists (known as arrays in other languages) are one of the compound data types that Python understands. Lists can be indexed, sliced and manipulated with other built-in functions. More about lists in Python\\xa03\\n\\n\\n# Python 3: Simple arithmetic\\r\\n>>> 1 / 2\\r\\n0.5\\r\\n>>> 2 ** 3\\r\\n8\\r\\n>>> 17 / 3  # classic division returns a float\\r\\n5.666666666666667\\r\\n>>> 17 // 3  # floor division\\r\\n5\\nIntuitive Interpretation\\nCalculations are simple with Python, and expression syntax is straightforward: the operators +, -, * and / work as expected; parentheses () can be used for grouping. More about simple math functions in Python\\xa03.\\n\\n\\n# For loop on a list\\r\\n>>> numbers = [2, 4, 6, 8]\\r\\n>>> product = 1\\r\\n>>> for number in numbers:\\r\\n...    product = product * number\\r\\n... \\r\\n>>> print(\\'The product is:\\', product)\\r\\nThe product is: 384\\nAll the Flow You’d Expect\\nPython knows the usual control flow statements that other languages speak — if, for, while and range — with some of its own twists, of course. More control flow tools in Python\\xa03\\n\\n\\n# Simple output (with Unicode)\\r\\n>>> print(\"Hello, I\\'m Python!\")\\r\\nHello, I\\'m Python!\\r\\n# Input, assignment\\r\\n>>> name = input(\\'What is your name?\\\\n\\')\\r\\nWhat is your name?\\r\\nPython\\r\\n>>> print(f\\'Hi, {name}.\\')\\r\\nHi, Python.\\r\\n\\nQuick & Easy to Learn\\nExperienced programmers in any other language can pick up Python very quickly, and beginners find the clean syntax and indentation structure easy to learn. Whet your appetite with our Python\\xa03 overview.\\n\\n\\n\\n\\n\\nPython is a programming language that lets you work quickly and integrate systems more effectively. Learn More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet Started\\nWhether you\\'re new to programming or an experienced developer, it\\'s easy to learn and use Python.\\nStart with our Beginner’s Guide\\n\\n\\nDownload\\nPython source code and installers are available for download for all versions!\\nLatest: Python 3.14.2\\n\\n\\nDocs\\nDocumentation for Python\\'s standard library, along with tutorials and guides, are available online.\\ndocs.python.org\\n\\n\\nJobs\\nLooking for work or have a Python related position that you\\'re trying to hire for? Our relaunched community-run job board is the place to go.\\njobs.python.org\\n\\n\\n\\n\\n\\nLatest News\\nMore\\n\\n\\n2026-01-08\\nPSF News: $500K+ Raised for Python for Everyone, PyCon US, & More!\\n\\n2025-12-16\\nPython 3.15.0 alpha 3\\n\\n2025-12-15\\nPSF News Special Edition: Python is For Everyone & PyCon US 2026\\n\\n2025-12-05\\nPython 3.14.2 and 3.13.11 are now available!\\n\\n2025-12-02\\nPython 3.13.10 is now available, too, you know!\\n\\n\\n\\n\\n\\nUpcoming Events\\nMore\\n\\n\\n2026-01-14\\nPython Meeting DÃ¼sseldorf\\n\\n2026-01-22\\nPython Leiden User Group\\n\\n2026-01-27\\nPyLadies Amsterdam: Robotics beginner class with MicroPython\\n\\n2026-01-31\\nPython Devroom @ FOSDEM 2026\\n\\n2026-02-20\\nPyCon Namibia 2026\\n\\n\\n\\n\\n\\n\\n\\nSuccess Stories\\nMore\\n\\n\\nPython programmability on Algorand makes the entire development lifecycle easier and means more affordable and efficient maintenance and upgrades going forward.\\n\\n\\n\\n\\nUsing Python to build a solution for instant tokenized real estate redemptions by Brian Whippo, Head of Developer Relations, Algorand Foundation\\n\\n\\n\\n\\n\\n\\n\\n\\nUse Python for…\\nMore\\n\\nWeb Development:\\r\\n        Django, Pyramid, Bottle, Tornado, Flask, Litestar, web2py\\nGUI Development:\\r\\n        tkInter, PyGObject, PyQt, PySide, Kivy, wxPython, DearPyGui\\nScientific and Numeric:\\r\\n        \\nSciPy, Pandas, IPython\\nSoftware Development:\\r\\n        Buildbot, Trac, Roundup\\nSystem Administration:\\r\\n        Ansible, Salt, OpenStack, xonsh\\n\\n\\n\\n\\n\\n\\n\\n>>> Python Software Foundation\\n\\nThe mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers. Learn more \\n\\nBecome a Member\\nDonate to the PSF\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n▲ Back to Top\\n\\n\\nAbout\\n\\nApplications\\nQuotes\\nGetting Started\\nHelp\\nPython Brochure\\n\\n\\n\\nDownloads\\n\\nAll releases\\nSource code\\nWindows\\nmacOS\\nAndroid\\nOther Platforms\\nLicense\\nAlternative Implementations\\n\\n\\n\\nDocumentation\\n\\nDocs\\nAudio/Visual Talks\\nBeginner\\'s Guide\\nFAQ\\nNon-English Docs\\nPEP Index\\nPython Books\\nPython Essays\\n\\n\\n\\nCommunity\\n\\nDiversity\\nMailing Lists\\nIRC\\nForums\\nPSF Annual Impact Report\\nPython Conferences\\nSpecial Interest Groups\\nPython Logo\\nPython Wiki\\nCode of Conduct\\nCommunity Awards\\nGet Involved\\nShared Stories\\n\\n\\n\\nSuccess Stories\\n\\nArts\\nBusiness\\nEducation\\nEngineering\\nGovernment\\nScientific\\nSoftware Development\\n\\n\\n\\nNews\\n\\nPython News\\nPSF Newsletter\\nPSF News\\nPyCon US News\\nNews from the Community\\n\\n\\n\\nEvents\\n\\nPython Events\\nUser Group Events\\nPython Events Archive\\nUser Group Events Archive\\nSubmit an Event\\n\\n\\n\\nContributing\\n\\nDeveloper\\'s Guide\\nIssue Tracker\\npython-dev list\\nCore Mentorship\\nReport a Security Issue\\n\\n\\n\\n▲ Back to Top\\n\\n \\n\\n\\n\\nHelp & General Contact\\nDiversity Initiatives\\nSubmit Website Bug\\n\\nStatus \\n\\n\\n\\n\\nCopyright ©2001-2026.\\n                            \\xa0Python Software Foundation\\n                            \\xa0Legal Statements\\n                            \\xa0Privacy Notice\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Multiple Web page\n",
    "web_loader= WebBaseLoader(web_paths=['https://www.google.com','http://www.python.org'])\n",
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6cbce7-278f-4108-bd8b-c441bff03be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebBaseLoader(web_path='https://www.google.com')\n",
    "\n",
    "VS\n",
    "\n",
    "WebBaseLoader(web_path='https://www.google.com', bs_kwargs=dict(parse_only= bs4.SoupStrainer(class_=('TagName')))\n",
    "\n",
    "              \n",
    "WebBaseLoader(web_path='https://www.google.com', bs_kwargs=dict(parse_only= bs4.SoupStrainer(class_=('TagName, TagName2, TagNAme3')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9aae19-8562-4d4c-ab99-9d1e2ec568d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL= 'http://lilianweng.github.io/posts/2023-09-23-agent/'\n",
    "\n",
    "loader=WebBaseLoader(web_path=(URL), bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"post-title\"))))\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c1719-76df-4406-8e7a-f77277834e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL= 'https://lilianweng.github.io/posts/2023-06-23-agent/'\n",
    "loader=WebBaseLoader(web_path=URL, bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"post-title\"))))\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51601567-8459-43bc-9820-1aeaa74affa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "WikipediaLoader(query='Question')  ---> loader_obj.load() --> data\n",
    "WikipediaLoader(query-'Question',load_max_docs=<count>)-> loader_obj.load()--> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b0897d5-8f2f-4993-86fe-15b04837a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ArxivLoader in module langchain_community.document_loaders.arxiv:\n",
      "\n",
      "class ArxivLoader(langchain_core.document_loaders.base.BaseLoader)\n",
      " |  ArxivLoader(\n",
      " |      query: str,\n",
      " |      doc_content_chars_max: Optional[int] = None,\n",
      " |      **kwargs: Any\n",
      " |  )\n",
      " |\n",
      " |  Load a query result from `Arxiv`.\n",
      " |  The loader converts the original PDF format into the text.\n",
      " |\n",
      " |  Setup:\n",
      " |      Install ``arxiv`` and ``PyMuPDF`` packages.\n",
      " |      ``PyMuPDF`` transforms PDF files downloaded from the arxiv.org site\n",
      " |      into the text format.\n",
      " |\n",
      " |      .. code-block:: bash\n",
      " |\n",
      " |          pip install -U arxiv pymupdf\n",
      " |\n",
      " |\n",
      " |  Instantiate:\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          from langchain_community.document_loaders import ArxivLoader\n",
      " |\n",
      " |          loader = ArxivLoader(\n",
      " |              query=\"reasoning\",\n",
      " |              # load_max_docs=2,\n",
      " |              # load_all_available_meta=False\n",
      " |          )\n",
      " |\n",
      " |  Load:\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          docs = loader.load()\n",
      " |          print(docs[0].page_content[:100])\n",
      " |          print(docs[0].metadata)\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |          Understanding the Reasoning Ability of Language Models\n",
      " |          From the Perspective of Reasoning Paths Aggre\n",
      " |          {\n",
      " |              'Published': '2024-02-29',\n",
      " |              'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      " |                      Perspective of Reasoning Paths Aggregation',\n",
      " |              'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      " |                      Wenhu Chen, William Yang Wang',\n",
      " |              'Summary': 'Pre-trained language models (LMs) are able to perform complex reasoning\n",
      " |                      without explicit fine-tuning...'\n",
      " |          }\n",
      " |\n",
      " |\n",
      " |  Lazy load:\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          docs = []\n",
      " |          docs_lazy = loader.lazy_load()\n",
      " |\n",
      " |          # async variant:\n",
      " |          # docs_lazy = await loader.alazy_load()\n",
      " |\n",
      " |          for doc in docs_lazy:\n",
      " |              docs.append(doc)\n",
      " |          print(docs[0].page_content[:100])\n",
      " |          print(docs[0].metadata)\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          Understanding the Reasoning Ability of Language Models\n",
      " |          From the Perspective of Reasoning Paths Aggre\n",
      " |          {\n",
      " |              'Published': '2024-02-29',\n",
      " |              'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      " |                      Perspective of Reasoning Paths Aggregation',\n",
      " |              'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      " |                      Wenhu Chen, William Yang Wang',\n",
      " |              'Summary': 'Pre-trained language models (LMs) are able to perform complex reasoning\n",
      " |                      without explicit fine-tuning...'\n",
      " |          }\n",
      " |\n",
      " |  Async load:\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          docs = await loader.aload()\n",
      " |          print(docs[0].page_content[:100])\n",
      " |          print(docs[0].metadata)\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          Understanding the Reasoning Ability of Language Models\n",
      " |          From the Perspective of Reasoning Paths Aggre\n",
      " |          {\n",
      " |              'Published': '2024-02-29',\n",
      " |              'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      " |                      Perspective of Reasoning Paths Aggregation',\n",
      " |              'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      " |                      Wenhu Chen, William Yang Wang',\n",
      " |              'Summary': 'Pre-trained language models (LMs) are able to perform complex reasoning\n",
      " |                      without explicit fine-tuning...'\n",
      " |          }\n",
      " |\n",
      " |  Use summaries of articles as docs:\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          from langchain_community.document_loaders import ArxivLoader\n",
      " |\n",
      " |          loader = ArxivLoader(\n",
      " |              query=\"reasoning\"\n",
      " |          )\n",
      " |\n",
      " |          docs = loader.get_summaries_as_docs()\n",
      " |          print(docs[0].page_content[:100])\n",
      " |          print(docs[0].metadata)\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          Pre-trained language models (LMs) are able to perform complex reasoning\n",
      " |          without explicit fine-tuning\n",
      " |          {\n",
      " |              'Entry ID': 'http://arxiv.org/abs/2402.03268v2',\n",
      " |              'Published': datetime.date(2024, 2, 29),\n",
      " |              'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      " |                      Perspective of Reasoning Paths Aggregation',\n",
      " |              'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      " |                      Wenhu Chen, William Yang Wang'\n",
      " |          }\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      ArxivLoader\n",
      " |      langchain_core.document_loaders.base.BaseLoader\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      query: str,\n",
      " |      doc_content_chars_max: Optional[int] = None,\n",
      " |      **kwargs: Any\n",
      " |  )\n",
      " |      Initialize with search query to find documents in the Arxiv.\n",
      " |      Supports all arguments of `ArxivAPIWrapper`.\n",
      " |\n",
      " |      Args:\n",
      " |          query: free text which used to find documents in the Arxiv\n",
      " |          doc_content_chars_max: cut limit for the length of a document's content\n",
      " |\n",
      " |  get_summaries_as_docs(self) -> List[langchain_core.documents.base.Document]\n",
      " |      Uses papers summaries as documents rather than source Arvix papers\n",
      " |\n",
      " |  lazy_load(self) -> Iterator[langchain_core.documents.base.Document]\n",
      " |      Lazy load Arvix documents\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.document_loaders.base.BaseLoader:\n",
      " |\n",
      " |  async alazy_load(self) -> 'AsyncIterator[Document]'\n",
      " |      A lazy loader for Documents.\n",
      " |\n",
      " |      Yields:\n",
      " |          the documents.\n",
      " |\n",
      " |  async aload(self) -> 'list[Document]'\n",
      " |      Load data into Document objects.\n",
      " |\n",
      " |      Returns:\n",
      " |          the documents.\n",
      " |\n",
      " |  load(self) -> 'list[Document]'\n",
      " |      Load data into Document objects.\n",
      " |\n",
      " |      Returns:\n",
      " |          the documents.\n",
      " |\n",
      " |  load_and_split(self, text_splitter: 'Optional[TextSplitter]' = None) -> 'list[Document]'\n",
      " |      Load Documents and split into chunks. Chunks are returned as Documents.\n",
      " |\n",
      " |      Do not override this method. It should be considered to be deprecated!\n",
      " |\n",
      " |      Args:\n",
      " |          text_splitter: TextSplitter instance to use for splitting documents.\n",
      " |              Defaults to RecursiveCharacterTextSplitter.\n",
      " |\n",
      " |      Raises:\n",
      " |          ImportError: If langchain-text-splitters is not installed\n",
      " |              and no text_splitter is provided.\n",
      " |\n",
      " |      Returns:\n",
      " |          List of Documents.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.document_loaders.base.BaseLoader:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ArxivLoader - research paper\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "help(ArxivLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2007f1-cf19-4005-9f33-6bc569cb54cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24759f-24fa-463c-b81f-19d87af8e5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352783f3-d10a-4fab-aff8-d7615aa22b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349d9b7-d72c-4596-885f-5118dbcacaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee24aca-a74b-49cc-ad99-75bca5a8fbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33effec-8ebb-4eca-93cf-de2df10c745a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d541580-3fbf-49cd-bc74-1431c9edff2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28362a40-48b4-49b4-aa0e-374dbb54cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Spark)",
   "language": "python",
   "name": "spark310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
