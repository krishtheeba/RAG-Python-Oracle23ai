{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79543954-b239-49a3-ba73-546610e94191",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG pipeline strictly PDF-only, so that:\n",
    "=========================================\n",
    "It never answers using pretrained model knowledge.\n",
    "\n",
    "It only answers from your loaded PDF chunks.\n",
    "\n",
    "If nothing relevant is found, it always says Answer not found in the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bafde1a4-69c8-403d-92c9-e54c8949835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: Explain what artificial intelligence means.\n",
      "=======================================\n",
      "\n",
      " Result 1:  (Similarity Score: 1.4850000143051147)\n",
      "---------------------------------------\n",
      "[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\n",
      "Advances in Neural Information Processing Systems, 2015.\n",
      "[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\n",
      "Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\n",
      "translation system: Bridging the gap between human and machine translation.  ...\n",
      "\n",
      " Result 2:  (Similarity Score: 1.5019999742507935)\n",
      "---------------------------------------\n",
      "architectures [38, 24, 15].\n",
      "Recurrent models typically factor computation along the symbol positions of the input and output\n",
      "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
      "states ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\n",
      "sequential nature precludes parallelization within training examples, w ...\n",
      "\n",
      " Result 3:  (Similarity Score: 1.5049999952316284)\n",
      "---------------------------------------\n",
      "(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\n",
      "layer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\n",
      "consider three desiderata.\n",
      "One is the total computational complexity per layer. Another is the amount of computation that can\n",
      "be parallelized, as measured by the minimum number of sequential operatio ...\n"
     ]
    }
   ],
   "source": [
    "#  Install (if not already)\n",
    "# pip install langchain langchain_community faiss-cpu sentence-transformers PyPDF2\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Step 1️: Load your PDF (or use any small sample PDF)\n",
    "loader = PyPDFLoader(\"C:\\\\Users\\\\karth\\\\attention.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Step 2️: Split text into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(documents)\n",
    "\n",
    "# Step 3️: Create embeddings using Hugging Face\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 4️: Build FAISS vector database\n",
    "vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "# Step 5️: Create retriever with threshold\n",
    "retriever_obj = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.2, \"k\": 3}\n",
    ")\n",
    "\n",
    "# Step 6️: Ask a question to test retrieval\n",
    "query = \"Explain what artificial intelligence means.\"\n",
    "\n",
    "\n",
    "search_results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(f\"\\n Query: {query}\")\n",
    "print(\"=======================================\")\n",
    "\n",
    "for i, (doc, score) in enumerate(search_results, start=1):\n",
    "    print(f\"\\n Result {i}:  (Similarity Score: {round(score, 3)})\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(doc.page_content[:400], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bd0ff-74e3-4ec1-aef9-7397f6beed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full Example: PDF Summarization using Groq (LangChain RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4da7d1-499d-4104-8fd7-dda27bd78c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 1: Install required packages\n",
    "# pip install langchain langchain_community langchain_groq sentence-transformers faiss-cpu PyPDF2\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "import os\n",
    "\n",
    "# Step 2: Set your Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"os.getenv('GROQ_API_KEY')\"\n",
    "\n",
    "#  Step 3: Load the PDF\n",
    "loader = PyPDFLoader(\"attention.pdf\")   # Replace with your own PDF filename\n",
    "documents = loader.load()\n",
    "print(f\" Loaded {len(documents)} pages from PDF\")\n",
    "\n",
    "#  Step 4: Split into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "docs = splitter.split_documents(documents)\n",
    "print(f\"Split into {len(docs)} chunks\")\n",
    "\n",
    "#  Step 5: Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 6: Create FAISS vectorstore\n",
    "vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "#  Step 7: Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.2, \"k\": 4}\n",
    ")\n",
    "\n",
    "#  Step 8: Initialize Groq LLM\n",
    "llm_model = ChatGroq(model=\"llama-3.1-8b-instant\", api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "#  Step 9: Create prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a professional document summarizer.\n",
    "Use ONLY the following context from the document to summarize the content.\n",
    "If you don’t find enough information, say “Information not found in the document.”\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User question:\n",
    "{input}\n",
    "\"\"\")\n",
    "\n",
    "#  Step 10: Create Stuff Documents Chain\n",
    "qa_chain = create_stuff_documents_chain(llm_model, prompt)\n",
    "\n",
    "#  Step 11: Combine Retriever + QA chain = RAG pipeline\n",
    "rag_chain = create_retrieval_chain(retriever, qa_chain)\n",
    "\n",
    "#  Step 12: Run query — ask for summary\n",
    "query = \"Summarize the key results and findings from this PDF.\"\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(\"\\n Final Summary:\\n\")\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
